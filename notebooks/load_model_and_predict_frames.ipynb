{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This notebook can be used to load a trained model and produce predictions for each frame in the dataset which will be stored as `frame_predictions.csv` inside the model folder.\n",
    "\n",
    "> You need to specify the experiment parameters including model id in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T16:42:48.478978Z",
     "start_time": "2020-05-14T16:42:48.471568Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "experiment = {\n",
    "             'architecture': 'video_lrcnn_frozen',\n",
    "             'dropout': 0.2,\n",
    "             'layer_1_size': 256,\n",
    "             'layer_2_size': 128,\n",
    "             'layer_3_size': 0,\n",
    "             'model_id': 5,\n",
    "             'pooling': 'max',\n",
    "             'pretrained_model_name': 'resnet50',\n",
    "             'sequence_length': 5,\n",
    "             'sequence_model': \"LSTM\",\n",
    "             'sequence_model_layers': 2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T16:42:49.022801Z",
     "start_time": "2020-05-14T16:42:49.018047Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# whether to log each feature and sequence status\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T16:42:49.291297Z",
     "start_time": "2020-05-14T16:42:49.273159Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import sys\n",
    "from shutil import rmtree\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T16:42:53.335646Z",
     "start_time": "2020-05-14T16:42:49.599447Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/alex/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/alex/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/alex/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/alex/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/alex/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/alex/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T16:42:53.348984Z",
     "start_time": "2020-05-14T16:42:53.341063Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup paths\n",
    "pwd = os.getcwd().replace(\"notebooks\",\"\")\n",
    "path_cache = pwd + 'cache/'\n",
    "path_data = pwd + 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T16:42:53.397960Z",
     "start_time": "2020-05-14T16:42:53.370871Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup logging\n",
    "# any explicit log messages or uncaught errors to stdout and file /logs.log\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(threadName)-12.12s] [%(levelname)-5.5s]  %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"{0}/{1}.log\".format(pwd, \"logs\")),\n",
    "        logging.StreamHandler()\n",
    "    ])\n",
    "# init logger\n",
    "logger = logging.getLogger()\n",
    "# make logger aware of any uncaught exceptions\n",
    "def handle_exception(exc_type, exc_value, exc_traceback):\n",
    "    if issubclass(exc_type, KeyboardInterrupt):\n",
    "        sys.__excepthook__(exc_type, exc_value, exc_traceback)\n",
    "        return\n",
    "\n",
    "    logger.error(\"Uncaught exception\", exc_info=(exc_type, exc_value, exc_traceback))\n",
    "sys.excepthook = handle_exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T16:42:54.742427Z",
     "start_time": "2020-05-14T16:42:53.400771Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from deepvideoclassification.architectures import Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T16:42:54.753507Z",
     "start_time": "2020-05-14T16:42:54.746630Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from deepvideoclassification.data import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model weights from file "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> e.g. /models/123/model_best.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T16:47:06.666776Z",
     "start_time": "2020-05-14T16:42:57.722643Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-14 18:42:57,731 [MainThread  ] [INFO ]  Loading data\n",
      "2020-05-14 18:42:57,786 [MainThread  ] [INFO ]  resizing vid 1/3 to 224x224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5   XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "{'architecture': 'video_lrcnn_frozen', 'dropout': 0.2, 'layer_1_size': 256, 'layer_2_size': 128, 'layer_3_size': 0, 'model_id': 5, 'pooling': 'max', 'pretrained_model_name': 'resnet50', 'sequence_length': 5, 'sequence_model': 'LSTM', 'sequence_model_layers': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-14 18:43:00,662 [MainThread  ] [INFO ]  resizing vid 2/3 to 224x224\n",
      "2020-05-14 18:43:02,348 [MainThread  ] [INFO ]  resizing vid 3/3 to 224x224\n",
      "2020-05-14 18:43:12,148 [MainThread  ] [INFO ]  Computing pretrained model features for video 1/3 using pretrained model: resnet50, pooling: max\n",
      "2020-05-14 18:44:45,179 [MainThread  ] [INFO ]  Computing pretrained model features for video 2/3 using pretrained model: resnet50, pooling: max\n",
      "2020-05-14 18:45:41,070 [MainThread  ] [INFO ]  Computing pretrained model features for video 3/3 using pretrained model: resnet50, pooling: max\n",
      "2020-05-14 18:47:06,040 [MainThread  ] [INFO ]  Loading features sequence data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=262, valid=170, test=281\n"
     ]
    }
   ],
   "source": [
    "print(str(experiment[\"model_id\"]) + \"   \" + \"X\"*60)\n",
    "print(experiment)\n",
    "\n",
    "architecture = Architecture(model_id = experiment['model_id'], \n",
    "                            architecture = experiment['architecture'], \n",
    "                            sequence_length = experiment['sequence_length'], \n",
    "                            pretrained_model_name = experiment['pretrained_model_name'],\n",
    "                            pooling = experiment['pooling'],\n",
    "                            sequence_model = experiment['sequence_model'],\n",
    "                            sequence_model_layers = experiment['sequence_model_layers'],\n",
    "                            layer_1_size = experiment['layer_1_size'],\n",
    "                            layer_2_size = experiment['layer_2_size'],\n",
    "                            layer_3_size = experiment['layer_3_size'],\n",
    "                            dropout = experiment['dropout'],\n",
    "                            verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T16:47:06.677838Z",
     "start_time": "2020-05-14T16:47:06.669567Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alex/Documents/Work/thesis/_code/Deep-Neural-Networks-for-Video-Classification/models/5/model_best.h5\n"
     ]
    }
   ],
   "source": [
    "print(architecture.path_model + \"model_best.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T16:47:10.728598Z",
     "start_time": "2020-05-14T16:47:06.688982Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load model weights\n",
    "architecture.model = load_model(architecture.path_model + \"model_best.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and predict on test frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T16:58:56.019842Z",
     "start_time": "2020-05-14T16:58:56.013524Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sequence_length = experiment['sequence_length']\n",
    "pretrained_model_name = experiment['pretrained_model_name']\n",
    "pooling = experiment['pooling']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T16:58:56.854930Z",
     "start_time": "2020-05-14T16:58:56.722637Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-14 18:58:56,774 [MainThread  ] [INFO ]  Features already cached: /Users/alex/Documents/Work/thesis/_code/Deep-Neural-Networks-for-Video-Classification/cache/features/resnet50/max/\n",
      "2020-05-14 18:58:56,777 [MainThread  ] [INFO ]  Loading features sequence data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=262, valid=170, test=281\n"
     ]
    }
   ],
   "source": [
    "# build feature cache if it doesn't already exist\n",
    "data = Data(sequence_length=sequence_length, \n",
    "            return_CNN_features=True,\n",
    "            pretrained_model_name = pretrained_model_name,\n",
    "            pooling=pooling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T16:58:57.635651Z",
     "start_time": "2020-05-14T16:58:57.630186Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = data.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T16:58:58.621842Z",
     "start_time": "2020-05-14T16:58:58.611181Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['noseal', 'seal']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get class names from data object\n",
    "class_names = []\n",
    "for k in sorted(data.label_map.keys()):\n",
    "    class_names.append(data.label_map[k])\n",
    "class_names = [c.replace(\"label_\",\"\") for c in class_names]\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T16:58:59.258892Z",
     "start_time": "2020-05-14T16:58:59.253841Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get list of videos\n",
    "videos = list(labels['video'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T16:59:14.029730Z",
     "start_time": "2020-05-14T16:59:14.023898Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_features_path(video):\n",
    "    return pwd + 'cache/features/' + experiment['pretrained_model_name'] + '/' + experiment['pooling'] + '/' + video + '.npy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LRCN or video concat frame predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T16:59:23.955050Z",
     "start_time": "2020-05-14T16:59:19.522956Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing frame predictions for video 1/3: s26-8164\n",
      "Computing frame predictions for video 2/3: s27-8212\n",
      "Computing frame predictions for video 3/3: s28-20\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### LRCN and video concat\n",
    "if experiment['architecture'] == 'video_lrcnn_frozen' or experiment['architecture'] == 'video_mlp_concat':\n",
    "    # collect predictions for each video\n",
    "    y_preds = []\n",
    "\n",
    "    for c, video in enumerate(videos):\n",
    "        print(\"Computing frame predictions for video {}/{}: {}\".format(c+1,len(videos),video))\n",
    "\n",
    "        # load features from disk\n",
    "        features = np.load(get_features_path(video))\n",
    "\n",
    "        dfs = []\n",
    "        for i in range(sequence_length-1, len(features)):\n",
    "\n",
    "            # get features for the clip\n",
    "            features_frames = features[i-sequence_length+1:i+1,]\n",
    "            features_frames = np.expand_dims(features_frames, axis=0)\n",
    "\n",
    "            # run through model\n",
    "            y_pred = architecture.model.predict(features_frames)\n",
    "\n",
    "            # create pred dataframe\n",
    "            df_pred = pd.DataFrame(y_pred[0]).T\n",
    "            df_pred.columns = class_names\n",
    "            df_pred.index = [i]\n",
    "            dfs.append(df_pred)\n",
    "\n",
    "        # join pred dataframe onto labels\n",
    "        y_pred = pd.concat(dfs)\n",
    "        y_pred['pred'] = y_pred.idxmax(axis=1)\n",
    "        # align labels index\n",
    "        y_labs = labels[labels['video']==video]\n",
    "        y_labs.reset_index(inplace=True,drop=True)\n",
    "        # join predictions on labels\n",
    "        y_pred = pd.merge(y_pred, y_labs, left_index=True,right_index=True,how='left')\n",
    "        y_pred['error'] = (y_pred['label'] != y_pred['pred']).astype(int)\n",
    "\n",
    "        y_preds.append(y_pred)\n",
    "\n",
    "    preds_all = pd.concat(y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## image_mlp_frozen frame predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T16:59:25.108641Z",
     "start_time": "2020-05-14T16:59:25.059510Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "### image mlp frozen\n",
    "if experiment['architecture'] == 'image_mlp_frozen':\n",
    "    # collect predictions for each video\n",
    "    y_preds = []\n",
    "\n",
    "    for c, video in enumerate(videos):\n",
    "        print(\"Computing frame predictions for video {}/{}: {}\".format(c+1,len(videos),video))\n",
    "\n",
    "        # load features from disk\n",
    "        features = np.load(get_features_path(video))\n",
    "\n",
    "        dfs = []\n",
    "        for i in range(0, len(features)):\n",
    "\n",
    "            # get features for the clip\n",
    "            features_frames = features[i,]\n",
    "            features_frames = np.expand_dims(features_frames, axis=0)\n",
    "\n",
    "            # run through model\n",
    "            y_pred = architecture.model.predict(features_frames)\n",
    "\n",
    "            # create pred dataframe\n",
    "            df_pred = pd.DataFrame(y_pred[0]).T\n",
    "            df_pred.columns = class_names\n",
    "            df_pred.index = [i]\n",
    "            dfs.append(df_pred)\n",
    "\n",
    "        # join pred dataframe onto labels\n",
    "        y_pred = pd.concat(dfs)\n",
    "        y_pred['pred'] = y_pred.idxmax(axis=1)\n",
    "        # align labels index\n",
    "        y_labs = labels[labels['video']==video]\n",
    "        y_labs.reset_index(inplace=True,drop=True)\n",
    "        # join predictions on labels\n",
    "        y_pred = pd.merge(y_pred, y_labs, left_index=True,right_index=True,how='left')\n",
    "        y_pred['error'] = (y_pred['label'] != y_pred['pred']).astype(int)\n",
    "\n",
    "        y_preds.append(y_pred)\n",
    "\n",
    "    preds_all = pd.concat(y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print some frame predictions and write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T16:59:27.718775Z",
     "start_time": "2020-05-14T16:59:27.691360Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noseal</th>\n",
       "      <th>seal</th>\n",
       "      <th>pred</th>\n",
       "      <th>video</th>\n",
       "      <th>frame</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.976137</td>\n",
       "      <td>0.023863</td>\n",
       "      <td>noseal</td>\n",
       "      <td>s26-8164</td>\n",
       "      <td>s26-8164-00005.jpeg</td>\n",
       "      <td>noseal</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.979143</td>\n",
       "      <td>0.020857</td>\n",
       "      <td>noseal</td>\n",
       "      <td>s26-8164</td>\n",
       "      <td>s26-8164-00006.jpeg</td>\n",
       "      <td>noseal</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.981652</td>\n",
       "      <td>0.018348</td>\n",
       "      <td>noseal</td>\n",
       "      <td>s26-8164</td>\n",
       "      <td>s26-8164-00007.jpeg</td>\n",
       "      <td>noseal</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.982266</td>\n",
       "      <td>0.017734</td>\n",
       "      <td>noseal</td>\n",
       "      <td>s26-8164</td>\n",
       "      <td>s26-8164-00008.jpeg</td>\n",
       "      <td>noseal</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.982857</td>\n",
       "      <td>0.017143</td>\n",
       "      <td>noseal</td>\n",
       "      <td>s26-8164</td>\n",
       "      <td>s26-8164-00009.jpeg</td>\n",
       "      <td>noseal</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     noseal      seal    pred     video                frame   label  split  \\\n",
       "4  0.976137  0.023863  noseal  s26-8164  s26-8164-00005.jpeg  noseal  train   \n",
       "5  0.979143  0.020857  noseal  s26-8164  s26-8164-00006.jpeg  noseal  train   \n",
       "6  0.981652  0.018348  noseal  s26-8164  s26-8164-00007.jpeg  noseal  train   \n",
       "7  0.982266  0.017734  noseal  s26-8164  s26-8164-00008.jpeg  noseal  train   \n",
       "8  0.982857  0.017143  noseal  s26-8164  s26-8164-00009.jpeg  noseal  train   \n",
       "\n",
       "   error  \n",
       "4      0  \n",
       "5      0  \n",
       "6      0  \n",
       "7      0  \n",
       "8      0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T16:59:29.165640Z",
     "start_time": "2020-05-14T16:59:29.133665Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.043478260869565216"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_all['error'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T16:59:29.839344Z",
     "start_time": "2020-05-14T16:59:29.810565Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.022900763358778626"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_all[preds_all['split'] == 'train']['error'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T16:59:45.053617Z",
     "start_time": "2020-05-14T16:59:45.041794Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.041176470588235294"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_all[preds_all['split'] == 'valid']['error'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T16:59:45.584256Z",
     "start_time": "2020-05-14T16:59:45.574181Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06405693950177936"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_all[preds_all['split'] == 'test']['error'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T16:59:53.447658Z",
     "start_time": "2020-05-14T16:59:53.432997Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds_all.to_csv(pwd + \"models/\" + str(experiment['model_id']) + '/frame_predictions.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
