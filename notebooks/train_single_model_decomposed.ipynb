{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T17:14:17.264442Z",
     "start_time": "2020-05-14T17:14:17.250090Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# whether to log each feature and sequence status\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T17:14:18.583218Z",
     "start_time": "2020-05-14T17:14:17.657048Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from keras.utils import to_categorical\n",
    "import sys\n",
    "\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T17:14:18.993048Z",
     "start_time": "2020-05-14T17:14:18.988996Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "__file__ = os.path.abspath('train_single_model_decomposed.ipynb')\n",
    "DNN_lib_path = Path(__file__).parents[1].__str__()\n",
    "path_features  = '/media/tiesbarendse/DATA/be_ts_k_3350_n_200_0404231811_features/'\n",
    "path_data  = '/media/tiesbarendse/DATA/be_ts_k_3350_n_200_0404231811'\n",
    "path_cache = DNN_lib_path + '/cache/'\n",
    "\n",
    "custom_model_name = 'ResNet50_pop_grids'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T17:14:19.880582Z",
     "start_time": "2020-05-14T17:14:19.867630Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup logging\n",
    "# any explicit log messages or uncaught errors to stdout and file /logs.log\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(threadName)-12.12s] [%(levelname)-5.5s]  %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(f\"{DNN_lib_path}/logs_{custom_model_name}_training.log\"),\n",
    "        logging.StreamHandler()\n",
    "    ])\n",
    "# init logger\n",
    "logger = logging.getLogger()\n",
    "# make logger aware of any uncaught exceptions\n",
    "def handle_exception(exc_type, exc_value, exc_traceback):\n",
    "    if issubclass(exc_type, KeyboardInterrupt):\n",
    "        sys.__excepthook__(exc_type, exc_value, exc_traceback)\n",
    "        return\n",
    "\n",
    "    logger.error(\"Uncaught exception\", exc_info=(exc_type, exc_value, exc_traceback))\n",
    "sys.excepthook = handle_exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T17:14:24.947193Z",
     "start_time": "2020-05-14T17:14:20.448078Z"
    }
   },
   "outputs": [],
   "source": [
    "from deepvideoclassification.architectures import Architecture\n",
    "from deepvideoclassification.data import Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Data Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>boarding_event</th>\n",
       "      <th>frame_index</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>535000</th>\n",
       "      <td>trajs_2017-03-01_Ut_3020_door_3</td>\n",
       "      <td>0</td>\n",
       "      <td>pre-deboarding</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535001</th>\n",
       "      <td>trajs_2017-03-01_Ut_3020_door_3</td>\n",
       "      <td>1</td>\n",
       "      <td>pre-deboarding</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535002</th>\n",
       "      <td>trajs_2017-03-01_Ut_3020_door_3</td>\n",
       "      <td>2</td>\n",
       "      <td>pre-deboarding</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535003</th>\n",
       "      <td>trajs_2017-03-01_Ut_3020_door_3</td>\n",
       "      <td>3</td>\n",
       "      <td>pre-deboarding</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535004</th>\n",
       "      <td>trajs_2017-03-01_Ut_3020_door_3</td>\n",
       "      <td>4</td>\n",
       "      <td>pre-deboarding</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95395</th>\n",
       "      <td>trajs_2018-06-08_Ut_3128_door_4</td>\n",
       "      <td>195</td>\n",
       "      <td>post-boarding</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95396</th>\n",
       "      <td>trajs_2018-06-08_Ut_3128_door_4</td>\n",
       "      <td>196</td>\n",
       "      <td>post-boarding</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95397</th>\n",
       "      <td>trajs_2018-06-08_Ut_3128_door_4</td>\n",
       "      <td>197</td>\n",
       "      <td>post-boarding</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95398</th>\n",
       "      <td>trajs_2018-06-08_Ut_3128_door_4</td>\n",
       "      <td>198</td>\n",
       "      <td>post-boarding</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95399</th>\n",
       "      <td>trajs_2018-06-08_Ut_3128_door_4</td>\n",
       "      <td>199</td>\n",
       "      <td>post-boarding</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>670000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         boarding_event  frame_index           label split\n",
       "535000  trajs_2017-03-01_Ut_3020_door_3            0  pre-deboarding   val\n",
       "535001  trajs_2017-03-01_Ut_3020_door_3            1  pre-deboarding   val\n",
       "535002  trajs_2017-03-01_Ut_3020_door_3            2  pre-deboarding   val\n",
       "535003  trajs_2017-03-01_Ut_3020_door_3            3  pre-deboarding   val\n",
       "535004  trajs_2017-03-01_Ut_3020_door_3            4  pre-deboarding   val\n",
       "...                                 ...          ...             ...   ...\n",
       "95395   trajs_2018-06-08_Ut_3128_door_4          195   post-boarding   NaN\n",
       "95396   trajs_2018-06-08_Ut_3128_door_4          196   post-boarding   NaN\n",
       "95397   trajs_2018-06-08_Ut_3128_door_4          197   post-boarding   NaN\n",
       "95398   trajs_2018-06-08_Ut_3128_door_4          198   post-boarding   NaN\n",
       "95399   trajs_2018-06-08_Ut_3128_door_4          199   post-boarding   NaN\n",
       "\n",
       "[670000 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df = pd.read_csv(path_data + '/labels_split.csv', usecols=['boarding_event','frame_index','label','split']).sort_values(['boarding_event', 'frame_index'])\n",
    "label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>boarding_event</th>\n",
       "      <th>frame_index</th>\n",
       "      <th>split</th>\n",
       "      <th>label_boarding</th>\n",
       "      <th>label_deboarding</th>\n",
       "      <th>label_phase-change</th>\n",
       "      <th>label_post-boarding</th>\n",
       "      <th>label_pre-deboarding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>535000</th>\n",
       "      <td>trajs_2017-03-01_Ut_3020_door_3</td>\n",
       "      <td>0</td>\n",
       "      <td>val</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535001</th>\n",
       "      <td>trajs_2017-03-01_Ut_3020_door_3</td>\n",
       "      <td>1</td>\n",
       "      <td>val</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535002</th>\n",
       "      <td>trajs_2017-03-01_Ut_3020_door_3</td>\n",
       "      <td>2</td>\n",
       "      <td>val</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535003</th>\n",
       "      <td>trajs_2017-03-01_Ut_3020_door_3</td>\n",
       "      <td>3</td>\n",
       "      <td>val</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535004</th>\n",
       "      <td>trajs_2017-03-01_Ut_3020_door_3</td>\n",
       "      <td>4</td>\n",
       "      <td>val</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95395</th>\n",
       "      <td>trajs_2018-06-08_Ut_3128_door_4</td>\n",
       "      <td>195</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95396</th>\n",
       "      <td>trajs_2018-06-08_Ut_3128_door_4</td>\n",
       "      <td>196</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95397</th>\n",
       "      <td>trajs_2018-06-08_Ut_3128_door_4</td>\n",
       "      <td>197</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95398</th>\n",
       "      <td>trajs_2018-06-08_Ut_3128_door_4</td>\n",
       "      <td>198</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95399</th>\n",
       "      <td>trajs_2018-06-08_Ut_3128_door_4</td>\n",
       "      <td>199</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>670000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         boarding_event  frame_index split  label_boarding   \n",
       "535000  trajs_2017-03-01_Ut_3020_door_3            0   val           False  \\\n",
       "535001  trajs_2017-03-01_Ut_3020_door_3            1   val           False   \n",
       "535002  trajs_2017-03-01_Ut_3020_door_3            2   val           False   \n",
       "535003  trajs_2017-03-01_Ut_3020_door_3            3   val           False   \n",
       "535004  trajs_2017-03-01_Ut_3020_door_3            4   val           False   \n",
       "...                                 ...          ...   ...             ...   \n",
       "95395   trajs_2018-06-08_Ut_3128_door_4          195   NaN           False   \n",
       "95396   trajs_2018-06-08_Ut_3128_door_4          196   NaN           False   \n",
       "95397   trajs_2018-06-08_Ut_3128_door_4          197   NaN           False   \n",
       "95398   trajs_2018-06-08_Ut_3128_door_4          198   NaN           False   \n",
       "95399   trajs_2018-06-08_Ut_3128_door_4          199   NaN           False   \n",
       "\n",
       "        label_deboarding  label_phase-change  label_post-boarding   \n",
       "535000             False               False                False  \\\n",
       "535001             False               False                False   \n",
       "535002             False               False                False   \n",
       "535003             False               False                False   \n",
       "535004             False               False                False   \n",
       "...                  ...                 ...                  ...   \n",
       "95395              False               False                 True   \n",
       "95396              False               False                 True   \n",
       "95397              False               False                 True   \n",
       "95398              False               False                 True   \n",
       "95399              False               False                 True   \n",
       "\n",
       "        label_pre-deboarding  \n",
       "535000                  True  \n",
       "535001                  True  \n",
       "535002                  True  \n",
       "535003                  True  \n",
       "535004                  True  \n",
       "...                      ...  \n",
       "95395                  False  \n",
       "95396                  False  \n",
       "95397                  False  \n",
       "95398                  False  \n",
       "95399                  False  \n",
       "\n",
       "[670000 rows x 8 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_dummied = pd.get_dummies(label_df, columns=['label'])\n",
    "labels_dummied \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerize_phase_dict = {\n",
    "    np.nan : 0,\n",
    "    'pre-deboarding' : 0,\n",
    "    'deboarding' : 1,\n",
    "    'phase-change' : 2,\n",
    "    'boarding' : 3,\n",
    "    'post-boarding' : 0\n",
    "}\n",
    "\n",
    "class Data(object):\n",
    "\n",
    "    def __init__(self, sequence_length,\n",
    "                 return_CNN_features=True,\n",
    "                 pretrained_model_name=None,\n",
    "                 pooling=None,\n",
    "                 frame_size=None,\n",
    "                 custom_model_name=None,\n",
    "                 _bed=False,\n",
    "                 verbose=True,\n",
    "                 return_generator = False):\n",
    "        \"\"\"\n",
    "        Data object constructor\n",
    "        \n",
    "        \n",
    "        :sequence_length: number of frames in sequence to be returned by Data object\n",
    "        :return_CNN_features: whether to return precomputed features or return frames (or sequences of features/frames if sequence_length>1)\n",
    "\n",
    "        :return_features: if True then return features (or sequences of feature) from pretrained model, if False then return frames (or sequences of frames)        \n",
    "        :pretrained_model_name: name of pretrained model (or None if not using pretrained model e.g. for 3D-CNN)\n",
    "        :pooling: name of pooling variant (or None if not using pretrained model e.g. for 3D-CNN)\n",
    "        :frame_size: size that frames are resized to (this is looked up for pretrained models)\n",
    "        :aug3mentation: whether to apply data augmentation (horizontal flips)\n",
    "        :oversampling: whether to apply oversampling to create class balance\n",
    "        \n",
    "        :model_weights_path: path to custom model weights if we want to load CNN model we've fine-tuned to produce features (e.g. for LRCNN)\n",
    "        :custom_model_name: custom output name to append to pretrained model name\n",
    "        \n",
    "        :return_generator: if True and sequence_length > 1 and return_CNN_features == False, then do not return dataset, instead construct h5 file with sequences for each split and return generator that samples from that (dataset of sequecne frames too big to load into memory)\n",
    "        :batch_size: size of batches that generator must return\n",
    "        \n",
    "        :verbose: whether to log details\n",
    "        \n",
    "        Notes: \n",
    "        * if pretrained_model_name != None and return_CNN_features=False then will first apply preprocessor to frames (or frame sequences)\n",
    "        * if return_generator = True and sequence_length > 1 and return_CNN_features == False, large h5 files will be created in cache before returning generator\n",
    "        \"\"\"\n",
    "\n",
    "        # required params\n",
    "        self.sequence_length = sequence_length\n",
    "        self.frame_size = frame_size\n",
    "\n",
    "        # optional params\n",
    "        self.pretrained_model_name = pretrained_model_name\n",
    "        self.pooling = pooling\n",
    "        self.return_CNN_features = return_CNN_features\n",
    "        self.custom_model_name = custom_model_name\n",
    "        self.return_generator = return_generator\n",
    "\n",
    "        self.bed = _bed\n",
    "        self.frame_size = frame_size\n",
    "\n",
    "        self.verbose = verbose\n",
    "\n",
    "        self.x_train = []\n",
    "        self.y_train = []\n",
    "        #\n",
    "        self.x_valid = []\n",
    "        self.y_valid = []\n",
    "        #\n",
    "        self.x_test = []\n",
    "        self.y_test = []\n",
    "\n",
    "        ################\n",
    "        ### Prepare data\n",
    "        ################\n",
    "\n",
    "        #Label loading\n",
    "        self.labels = pd.read_csv(path_data + '/labels_split.csv', usecols=['boarding_event','frame_index','label','split']).sort_values(['boarding_event', 'frame_index'])\n",
    "        \n",
    "        # pull number of classes from labels shape\n",
    "        self.num_classes = len(list(numerize_phase_dict.values()))\n",
    "\n",
    "        # create dict mapping video to train/valid/test split assignment\n",
    "        video_splits = self.labels[['boarding_event', 'split']].drop_duplicates()\n",
    "        video_splits.set_index(\"boarding_event\", inplace=True)\n",
    "        video_splits = video_splits.to_dict()['split']\n",
    "        self.video_splits = video_splits\n",
    "\n",
    "        ###################################\n",
    "        ### load features / build sequences\n",
    "        ###################################\n",
    "\n",
    "        # load features/frames from all videos and concat into big array for each of train, valid and test\n",
    "        assert self.return_CNN_features\n",
    "\n",
    "        if verbose:\n",
    "            logging.info(\n",
    "                \"Loading features sequence data into memory [may take a few minutes]\")\n",
    "\n",
    "        #####################\n",
    "        ### feature sequences\n",
    "        #####################\n",
    "\n",
    "        bes_names = [be[:-6] for be in os.listdir(path_features)]\n",
    "\n",
    "        # loop over all vids and load precomputed features into memory as sequences\n",
    "        for c, be_name in enumerate(bes_names[:500]):\n",
    "\n",
    "            path_be_features = f'{path_features}/{be_name}_f.npy'\n",
    "\n",
    "            if verbose:\n",
    "                logging.info(\"Loading features sequence data into memory {}/{}\".format(c+1,len(bes_names)))\n",
    "\n",
    "            ### create sequence: features\n",
    "            # load precomputed features\n",
    "            features = np.load(path_be_features)\n",
    "            # build sequences\n",
    "            x = []\n",
    "            for i in range(self.sequence_length, len(features) + 1):\n",
    "                x.append(features[i-self.sequence_length:i])\n",
    "            x = np.array(x)\n",
    "            \n",
    "\n",
    "            # temp lists to store sequences\n",
    "            be_labels = self.labels.loc[self.labels.boarding_event == be_name]\n",
    "            y = []\n",
    "            for i in range(self.sequence_length, len(be_labels) + 1):\n",
    "                label = be_labels.label.iloc[i-1]\n",
    "                y.append(label)\n",
    "            y = np.array(list(map(numerize_phase_dict.get, y)))\n",
    "            y = to_categorical(y, num_classes=self.num_classes)\n",
    "\n",
    "            assert len(x) == len(y), f'Length of features ({len(x)}) does not match length of labels ({len(y)})'\n",
    "\n",
    "            ### build output\n",
    "            if self.video_splits[be_name] == \"train\":\n",
    "                self.x_train.append(x)\n",
    "                self.y_train.append(y)\n",
    "            if self.video_splits[be_name] == \"valid\":\n",
    "                self.x_valid.append(x)\n",
    "                self.y_valid.append(y)\n",
    "            if self.video_splits[be_name] == \"test\":\n",
    "                self.x_test.append(x)\n",
    "                self.y_test.append(y)\n",
    "\n",
    "        #################################\n",
    "        ### get file paths for each split\n",
    "        #################################\n",
    "        #\n",
    "        # Note: only makes sense for sequence_length = 1\n",
    "\n",
    "        # get file paths: train\n",
    "        dflab = self.labels[self.labels['split'] == 'train']\n",
    "        self.paths_train = list(\n",
    "            path_data + dflab['boarding_event'] + \"/\" + str(dflab['frame_index']))\n",
    "\n",
    "        # get file paths: valid\n",
    "        dflab = self.labels[self.labels['split'] == 'valid']\n",
    "        self.paths_valid = list(\n",
    "            path_data + dflab['boarding_event'] + \"/\" + str(dflab['frame_index']))\n",
    "\n",
    "        # get file paths: test\n",
    "        dflab = self.labels[self.labels['split'] == 'test']\n",
    "        self.paths_test = list(\n",
    "            path_data + dflab['boarding_event'] + \"/\" + str(dflab['frame_index']))\n",
    "\n",
    "        #################################################\n",
    "        ### reshape list outputs (if not using generator)\n",
    "        #################################################\n",
    "\n",
    "        ## e.g. (9846, 224, 224, 3) for frames [return_CNN_features=True]\n",
    "        ## or  (9846, 512) for features [return_CNN_features=False]\n",
    "        self.x_train = np.concatenate(self.x_train, axis=0)\n",
    "        self.y_train = np.concatenate(self.y_train, axis=0)\n",
    "        self.x_valid = np.concatenate(self.x_valid, axis=0)\n",
    "        self.y_valid = np.concatenate(self.y_valid, axis=0)\n",
    "        self.x_test = np.concatenate(self.x_test, axis=0)\n",
    "        self.y_test = np.concatenate(self.y_test, axis=0)\n",
    "\n",
    "        self.total_rows_train = len(self.x_train)\n",
    "        self.total_rows_valid = len(self.x_valid)\n",
    "        self.total_rows_test = len(self.x_test)\n",
    "\n",
    "        # shuffle train and validation set\n",
    "        self.x_train, self.y_train = shuffle(self.x_train, self.y_train)\n",
    "        self.x_valid, self.y_valid = shuffle(self.x_valid, self.y_valid)\n",
    "\n",
    "        # update progress\n",
    "        if self.verbose:\n",
    "            print(\"Done initializing data with #samples: train={}, valid={}, test={}\".format(\n",
    "                self.total_rows_train, self.total_rows_valid, self.total_rows_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = {\n",
    "    'architecture': 'video_mlp_concat',\n",
    "    'dropout': 0.2,\n",
    "    'layer_1_size': 256,\n",
    "    'layer_2_size': 512,\n",
    "    'layer_3_size': 256,\n",
    "    'model_id': 1,\n",
    "    'pooling': 'max',\n",
    "    'pretrained_model_name': 'resnet50',\n",
    "    'custom_model_name': custom_model_name,\n",
    "    'path_features': f'/cache/{custom_model_name}',\n",
    "    'sequence_length': 20,\n",
    "    'sequence_model': \"LSTM\",\n",
    "    'sequence_model_layers': 3,\n",
    "    'frame_size': (32, 32)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T17:15:28.835943Z",
     "start_time": "2020-05-14T17:14:48.938251Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 20:53:23,104 [MainThread  ] [INFO ]  Loading features sequence data into memory [may take a few minutes]\n",
      "2023-04-05 20:53:23,108 [MainThread  ] [INFO ]  Loading features sequence data into memory 1/2374\n",
      "2023-04-05 20:53:23,150 [MainThread  ] [INFO ]  Loading features sequence data into memory 2/2374\n",
      "2023-04-05 20:53:23,198 [MainThread  ] [INFO ]  Loading features sequence data into memory 3/2374\n",
      "2023-04-05 20:53:23,245 [MainThread  ] [INFO ]  Loading features sequence data into memory 4/2374\n",
      "2023-04-05 20:53:23,291 [MainThread  ] [INFO ]  Loading features sequence data into memory 5/2374\n",
      "2023-04-05 20:53:23,343 [MainThread  ] [INFO ]  Loading features sequence data into memory 6/2374\n",
      "2023-04-05 20:53:23,409 [MainThread  ] [INFO ]  Loading features sequence data into memory 7/2374\n",
      "2023-04-05 20:53:23,464 [MainThread  ] [INFO ]  Loading features sequence data into memory 8/2374\n",
      "2023-04-05 20:53:23,523 [MainThread  ] [INFO ]  Loading features sequence data into memory 9/2374\n",
      "2023-04-05 20:53:23,572 [MainThread  ] [INFO ]  Loading features sequence data into memory 10/2374\n",
      "2023-04-05 20:53:23,677 [MainThread  ] [INFO ]  Loading features sequence data into memory 11/2374\n",
      "2023-04-05 20:53:23,797 [MainThread  ] [INFO ]  Loading features sequence data into memory 12/2374\n",
      "2023-04-05 20:53:23,945 [MainThread  ] [INFO ]  Loading features sequence data into memory 13/2374\n",
      "2023-04-05 20:53:24,236 [MainThread  ] [INFO ]  Loading features sequence data into memory 14/2374\n",
      "2023-04-05 20:53:24,280 [MainThread  ] [INFO ]  Loading features sequence data into memory 15/2374\n",
      "2023-04-05 20:53:24,324 [MainThread  ] [INFO ]  Loading features sequence data into memory 16/2374\n",
      "2023-04-05 20:53:24,535 [MainThread  ] [INFO ]  Loading features sequence data into memory 17/2374\n",
      "2023-04-05 20:53:24,699 [MainThread  ] [INFO ]  Loading features sequence data into memory 18/2374\n",
      "2023-04-05 20:53:24,933 [MainThread  ] [INFO ]  Loading features sequence data into memory 19/2374\n",
      "2023-04-05 20:53:25,076 [MainThread  ] [INFO ]  Loading features sequence data into memory 20/2374\n",
      "2023-04-05 20:53:25,178 [MainThread  ] [INFO ]  Loading features sequence data into memory 21/2374\n",
      "2023-04-05 20:53:25,319 [MainThread  ] [INFO ]  Loading features sequence data into memory 22/2374\n",
      "2023-04-05 20:53:25,390 [MainThread  ] [INFO ]  Loading features sequence data into memory 23/2374\n",
      "2023-04-05 20:53:25,448 [MainThread  ] [INFO ]  Loading features sequence data into memory 24/2374\n",
      "2023-04-05 20:53:25,488 [MainThread  ] [INFO ]  Loading features sequence data into memory 25/2374\n",
      "2023-04-05 20:53:25,544 [MainThread  ] [INFO ]  Loading features sequence data into memory 26/2374\n",
      "2023-04-05 20:53:25,606 [MainThread  ] [INFO ]  Loading features sequence data into memory 27/2374\n",
      "2023-04-05 20:53:25,670 [MainThread  ] [INFO ]  Loading features sequence data into memory 28/2374\n",
      "2023-04-05 20:53:25,744 [MainThread  ] [INFO ]  Loading features sequence data into memory 29/2374\n",
      "2023-04-05 20:53:25,799 [MainThread  ] [INFO ]  Loading features sequence data into memory 30/2374\n",
      "2023-04-05 20:53:26,056 [MainThread  ] [INFO ]  Loading features sequence data into memory 31/2374\n",
      "2023-04-05 20:53:26,206 [MainThread  ] [INFO ]  Loading features sequence data into memory 32/2374\n",
      "2023-04-05 20:53:26,259 [MainThread  ] [INFO ]  Loading features sequence data into memory 33/2374\n",
      "2023-04-05 20:53:26,393 [MainThread  ] [INFO ]  Loading features sequence data into memory 34/2374\n",
      "2023-04-05 20:53:26,584 [MainThread  ] [INFO ]  Loading features sequence data into memory 35/2374\n",
      "2023-04-05 20:53:26,636 [MainThread  ] [INFO ]  Loading features sequence data into memory 36/2374\n",
      "2023-04-05 20:53:26,924 [MainThread  ] [INFO ]  Loading features sequence data into memory 37/2374\n",
      "2023-04-05 20:53:27,120 [MainThread  ] [INFO ]  Loading features sequence data into memory 38/2374\n",
      "2023-04-05 20:53:27,416 [MainThread  ] [INFO ]  Loading features sequence data into memory 39/2374\n",
      "2023-04-05 20:53:27,559 [MainThread  ] [INFO ]  Loading features sequence data into memory 40/2374\n",
      "2023-04-05 20:53:27,798 [MainThread  ] [INFO ]  Loading features sequence data into memory 41/2374\n",
      "2023-04-05 20:53:28,015 [MainThread  ] [INFO ]  Loading features sequence data into memory 42/2374\n",
      "2023-04-05 20:53:28,199 [MainThread  ] [INFO ]  Loading features sequence data into memory 43/2374\n",
      "2023-04-05 20:53:28,565 [MainThread  ] [INFO ]  Loading features sequence data into memory 44/2374\n",
      "2023-04-05 20:53:28,806 [MainThread  ] [INFO ]  Loading features sequence data into memory 45/2374\n",
      "2023-04-05 20:53:29,019 [MainThread  ] [INFO ]  Loading features sequence data into memory 46/2374\n",
      "2023-04-05 20:53:29,212 [MainThread  ] [INFO ]  Loading features sequence data into memory 47/2374\n",
      "2023-04-05 20:53:29,432 [MainThread  ] [INFO ]  Loading features sequence data into memory 48/2374\n",
      "2023-04-05 20:53:29,517 [MainThread  ] [INFO ]  Loading features sequence data into memory 49/2374\n",
      "2023-04-05 20:53:30,048 [MainThread  ] [INFO ]  Loading features sequence data into memory 50/2374\n",
      "2023-04-05 20:53:30,128 [MainThread  ] [INFO ]  Loading features sequence data into memory 51/2374\n",
      "2023-04-05 20:53:30,210 [MainThread  ] [INFO ]  Loading features sequence data into memory 52/2374\n",
      "2023-04-05 20:53:30,278 [MainThread  ] [INFO ]  Loading features sequence data into memory 53/2374\n",
      "2023-04-05 20:53:30,346 [MainThread  ] [INFO ]  Loading features sequence data into memory 54/2374\n",
      "2023-04-05 20:53:30,422 [MainThread  ] [INFO ]  Loading features sequence data into memory 55/2374\n",
      "2023-04-05 20:53:30,528 [MainThread  ] [INFO ]  Loading features sequence data into memory 56/2374\n",
      "2023-04-05 20:53:30,653 [MainThread  ] [INFO ]  Loading features sequence data into memory 57/2374\n",
      "2023-04-05 20:53:30,760 [MainThread  ] [INFO ]  Loading features sequence data into memory 58/2374\n",
      "2023-04-05 20:53:30,849 [MainThread  ] [INFO ]  Loading features sequence data into memory 59/2374\n",
      "2023-04-05 20:53:30,929 [MainThread  ] [INFO ]  Loading features sequence data into memory 60/2374\n",
      "2023-04-05 20:53:31,009 [MainThread  ] [INFO ]  Loading features sequence data into memory 61/2374\n",
      "2023-04-05 20:53:31,063 [MainThread  ] [INFO ]  Loading features sequence data into memory 62/2374\n",
      "2023-04-05 20:53:31,162 [MainThread  ] [INFO ]  Loading features sequence data into memory 63/2374\n",
      "2023-04-05 20:53:31,314 [MainThread  ] [INFO ]  Loading features sequence data into memory 64/2374\n",
      "2023-04-05 20:53:31,447 [MainThread  ] [INFO ]  Loading features sequence data into memory 65/2374\n",
      "2023-04-05 20:53:31,520 [MainThread  ] [INFO ]  Loading features sequence data into memory 66/2374\n",
      "2023-04-05 20:53:32,063 [MainThread  ] [INFO ]  Loading features sequence data into memory 67/2374\n",
      "2023-04-05 20:53:32,199 [MainThread  ] [INFO ]  Loading features sequence data into memory 68/2374\n",
      "2023-04-05 20:53:32,313 [MainThread  ] [INFO ]  Loading features sequence data into memory 69/2374\n",
      "2023-04-05 20:53:32,367 [MainThread  ] [INFO ]  Loading features sequence data into memory 70/2374\n",
      "2023-04-05 20:53:32,699 [MainThread  ] [INFO ]  Loading features sequence data into memory 71/2374\n",
      "2023-04-05 20:53:32,860 [MainThread  ] [INFO ]  Loading features sequence data into memory 72/2374\n",
      "2023-04-05 20:53:32,992 [MainThread  ] [INFO ]  Loading features sequence data into memory 73/2374\n",
      "2023-04-05 20:53:34,031 [MainThread  ] [INFO ]  Loading features sequence data into memory 74/2374\n",
      "2023-04-05 20:53:34,087 [MainThread  ] [INFO ]  Loading features sequence data into memory 75/2374\n",
      "2023-04-05 20:53:34,233 [MainThread  ] [INFO ]  Loading features sequence data into memory 76/2374\n",
      "2023-04-05 20:53:35,068 [MainThread  ] [INFO ]  Loading features sequence data into memory 77/2374\n",
      "2023-04-05 20:53:35,341 [MainThread  ] [INFO ]  Loading features sequence data into memory 78/2374\n",
      "2023-04-05 20:53:35,630 [MainThread  ] [INFO ]  Loading features sequence data into memory 79/2374\n",
      "2023-04-05 20:53:35,723 [MainThread  ] [INFO ]  Loading features sequence data into memory 80/2374\n",
      "2023-04-05 20:53:36,105 [MainThread  ] [INFO ]  Loading features sequence data into memory 81/2374\n",
      "2023-04-05 20:53:36,163 [MainThread  ] [INFO ]  Loading features sequence data into memory 82/2374\n",
      "2023-04-05 20:53:36,613 [MainThread  ] [INFO ]  Loading features sequence data into memory 83/2374\n",
      "2023-04-05 20:53:36,810 [MainThread  ] [INFO ]  Loading features sequence data into memory 84/2374\n",
      "2023-04-05 20:53:37,169 [MainThread  ] [INFO ]  Loading features sequence data into memory 85/2374\n",
      "2023-04-05 20:53:37,271 [MainThread  ] [INFO ]  Loading features sequence data into memory 86/2374\n",
      "2023-04-05 20:53:37,324 [MainThread  ] [INFO ]  Loading features sequence data into memory 87/2374\n",
      "2023-04-05 20:53:37,385 [MainThread  ] [INFO ]  Loading features sequence data into memory 88/2374\n",
      "2023-04-05 20:53:37,559 [MainThread  ] [INFO ]  Loading features sequence data into memory 89/2374\n",
      "2023-04-05 20:53:38,000 [MainThread  ] [INFO ]  Loading features sequence data into memory 90/2374\n",
      "2023-04-05 20:53:38,210 [MainThread  ] [INFO ]  Loading features sequence data into memory 91/2374\n",
      "2023-04-05 20:53:38,390 [MainThread  ] [INFO ]  Loading features sequence data into memory 92/2374\n",
      "2023-04-05 20:53:38,442 [MainThread  ] [INFO ]  Loading features sequence data into memory 93/2374\n",
      "2023-04-05 20:53:38,799 [MainThread  ] [INFO ]  Loading features sequence data into memory 94/2374\n",
      "2023-04-05 20:53:38,951 [MainThread  ] [INFO ]  Loading features sequence data into memory 95/2374\n",
      "2023-04-05 20:53:39,128 [MainThread  ] [INFO ]  Loading features sequence data into memory 96/2374\n",
      "2023-04-05 20:53:39,264 [MainThread  ] [INFO ]  Loading features sequence data into memory 97/2374\n",
      "2023-04-05 20:53:39,597 [MainThread  ] [INFO ]  Loading features sequence data into memory 98/2374\n",
      "2023-04-05 20:53:40,057 [MainThread  ] [INFO ]  Loading features sequence data into memory 99/2374\n",
      "2023-04-05 20:53:40,426 [MainThread  ] [INFO ]  Loading features sequence data into memory 100/2374\n",
      "2023-04-05 20:53:40,651 [MainThread  ] [INFO ]  Loading features sequence data into memory 101/2374\n",
      "2023-04-05 20:53:40,733 [MainThread  ] [INFO ]  Loading features sequence data into memory 102/2374\n",
      "2023-04-05 20:53:40,897 [MainThread  ] [INFO ]  Loading features sequence data into memory 103/2374\n",
      "2023-04-05 20:53:41,039 [MainThread  ] [INFO ]  Loading features sequence data into memory 104/2374\n",
      "2023-04-05 20:53:41,494 [MainThread  ] [INFO ]  Loading features sequence data into memory 105/2374\n",
      "2023-04-05 20:53:41,934 [MainThread  ] [INFO ]  Loading features sequence data into memory 106/2374\n",
      "2023-04-05 20:53:42,149 [MainThread  ] [INFO ]  Loading features sequence data into memory 107/2374\n",
      "2023-04-05 20:53:42,336 [MainThread  ] [INFO ]  Loading features sequence data into memory 108/2374\n",
      "2023-04-05 20:53:42,653 [MainThread  ] [INFO ]  Loading features sequence data into memory 109/2374\n",
      "2023-04-05 20:53:42,745 [MainThread  ] [INFO ]  Loading features sequence data into memory 110/2374\n",
      "2023-04-05 20:53:42,915 [MainThread  ] [INFO ]  Loading features sequence data into memory 111/2374\n",
      "2023-04-05 20:53:43,207 [MainThread  ] [INFO ]  Loading features sequence data into memory 112/2374\n",
      "2023-04-05 20:53:43,515 [MainThread  ] [INFO ]  Loading features sequence data into memory 113/2374\n",
      "2023-04-05 20:53:43,574 [MainThread  ] [INFO ]  Loading features sequence data into memory 114/2374\n",
      "2023-04-05 20:53:43,890 [MainThread  ] [INFO ]  Loading features sequence data into memory 115/2374\n",
      "2023-04-05 20:53:44,403 [MainThread  ] [INFO ]  Loading features sequence data into memory 116/2374\n",
      "2023-04-05 20:53:45,046 [MainThread  ] [INFO ]  Loading features sequence data into memory 117/2374\n",
      "2023-04-05 20:53:45,807 [MainThread  ] [INFO ]  Loading features sequence data into memory 118/2374\n",
      "2023-04-05 20:53:45,946 [MainThread  ] [INFO ]  Loading features sequence data into memory 119/2374\n",
      "2023-04-05 20:53:46,093 [MainThread  ] [INFO ]  Loading features sequence data into memory 120/2374\n",
      "2023-04-05 20:53:46,303 [MainThread  ] [INFO ]  Loading features sequence data into memory 121/2374\n",
      "2023-04-05 20:53:47,004 [MainThread  ] [INFO ]  Loading features sequence data into memory 122/2374\n",
      "2023-04-05 20:53:47,083 [MainThread  ] [INFO ]  Loading features sequence data into memory 123/2374\n",
      "2023-04-05 20:53:47,135 [MainThread  ] [INFO ]  Loading features sequence data into memory 124/2374\n",
      "2023-04-05 20:53:48,685 [MainThread  ] [INFO ]  Loading features sequence data into memory 125/2374\n",
      "2023-04-05 20:53:48,942 [MainThread  ] [INFO ]  Loading features sequence data into memory 126/2374\n",
      "2023-04-05 20:53:49,185 [MainThread  ] [INFO ]  Loading features sequence data into memory 127/2374\n",
      "2023-04-05 20:53:49,381 [MainThread  ] [INFO ]  Loading features sequence data into memory 128/2374\n",
      "2023-04-05 20:53:49,866 [MainThread  ] [INFO ]  Loading features sequence data into memory 129/2374\n",
      "2023-04-05 20:53:50,134 [MainThread  ] [INFO ]  Loading features sequence data into memory 130/2374\n",
      "2023-04-05 20:53:50,187 [MainThread  ] [INFO ]  Loading features sequence data into memory 131/2374\n",
      "2023-04-05 20:53:50,333 [MainThread  ] [INFO ]  Loading features sequence data into memory 132/2374\n",
      "2023-04-05 20:53:50,547 [MainThread  ] [INFO ]  Loading features sequence data into memory 133/2374\n",
      "2023-04-05 20:53:50,755 [MainThread  ] [INFO ]  Loading features sequence data into memory 134/2374\n",
      "2023-04-05 20:53:50,950 [MainThread  ] [INFO ]  Loading features sequence data into memory 135/2374\n",
      "2023-04-05 20:53:51,173 [MainThread  ] [INFO ]  Loading features sequence data into memory 136/2374\n",
      "2023-04-05 20:53:51,227 [MainThread  ] [INFO ]  Loading features sequence data into memory 137/2374\n",
      "2023-04-05 20:53:52,786 [MainThread  ] [INFO ]  Loading features sequence data into memory 138/2374\n",
      "2023-04-05 20:53:52,836 [MainThread  ] [INFO ]  Loading features sequence data into memory 139/2374\n",
      "2023-04-05 20:53:52,912 [MainThread  ] [INFO ]  Loading features sequence data into memory 140/2374\n",
      "2023-04-05 20:53:54,190 [MainThread  ] [INFO ]  Loading features sequence data into memory 141/2374\n",
      "2023-04-05 20:53:54,355 [MainThread  ] [INFO ]  Loading features sequence data into memory 142/2374\n",
      "2023-04-05 20:53:55,299 [MainThread  ] [INFO ]  Loading features sequence data into memory 143/2374\n",
      "2023-04-05 20:53:55,355 [MainThread  ] [INFO ]  Loading features sequence data into memory 144/2374\n",
      "2023-04-05 20:53:55,430 [MainThread  ] [INFO ]  Loading features sequence data into memory 145/2374\n",
      "2023-04-05 20:53:55,495 [MainThread  ] [INFO ]  Loading features sequence data into memory 146/2374\n",
      "2023-04-05 20:53:55,561 [MainThread  ] [INFO ]  Loading features sequence data into memory 147/2374\n",
      "2023-04-05 20:53:55,642 [MainThread  ] [INFO ]  Loading features sequence data into memory 148/2374\n",
      "2023-04-05 20:53:56,049 [MainThread  ] [INFO ]  Loading features sequence data into memory 149/2374\n",
      "2023-04-05 20:53:56,217 [MainThread  ] [INFO ]  Loading features sequence data into memory 150/2374\n",
      "2023-04-05 20:53:56,444 [MainThread  ] [INFO ]  Loading features sequence data into memory 151/2374\n",
      "2023-04-05 20:53:56,553 [MainThread  ] [INFO ]  Loading features sequence data into memory 152/2374\n",
      "2023-04-05 20:53:56,605 [MainThread  ] [INFO ]  Loading features sequence data into memory 153/2374\n",
      "2023-04-05 20:53:56,772 [MainThread  ] [INFO ]  Loading features sequence data into memory 154/2374\n",
      "2023-04-05 20:53:56,984 [MainThread  ] [INFO ]  Loading features sequence data into memory 155/2374\n",
      "2023-04-05 20:53:57,130 [MainThread  ] [INFO ]  Loading features sequence data into memory 156/2374\n",
      "2023-04-05 20:53:57,268 [MainThread  ] [INFO ]  Loading features sequence data into memory 157/2374\n",
      "2023-04-05 20:53:57,386 [MainThread  ] [INFO ]  Loading features sequence data into memory 158/2374\n",
      "2023-04-05 20:53:57,533 [MainThread  ] [INFO ]  Loading features sequence data into memory 159/2374\n",
      "2023-04-05 20:53:57,712 [MainThread  ] [INFO ]  Loading features sequence data into memory 160/2374\n",
      "2023-04-05 20:53:58,017 [MainThread  ] [INFO ]  Loading features sequence data into memory 161/2374\n",
      "2023-04-05 20:53:59,147 [MainThread  ] [INFO ]  Loading features sequence data into memory 162/2374\n",
      "2023-04-05 20:53:59,248 [MainThread  ] [INFO ]  Loading features sequence data into memory 163/2374\n",
      "2023-04-05 20:54:00,524 [MainThread  ] [INFO ]  Loading features sequence data into memory 164/2374\n",
      "2023-04-05 20:54:01,366 [MainThread  ] [INFO ]  Loading features sequence data into memory 165/2374\n",
      "2023-04-05 20:54:01,612 [MainThread  ] [INFO ]  Loading features sequence data into memory 166/2374\n",
      "2023-04-05 20:54:01,667 [MainThread  ] [INFO ]  Loading features sequence data into memory 167/2374\n",
      "2023-04-05 20:54:01,971 [MainThread  ] [INFO ]  Loading features sequence data into memory 168/2374\n",
      "2023-04-05 20:54:02,047 [MainThread  ] [INFO ]  Loading features sequence data into memory 169/2374\n",
      "2023-04-05 20:54:02,296 [MainThread  ] [INFO ]  Loading features sequence data into memory 170/2374\n",
      "2023-04-05 20:54:02,555 [MainThread  ] [INFO ]  Loading features sequence data into memory 171/2374\n",
      "2023-04-05 20:54:02,860 [MainThread  ] [INFO ]  Loading features sequence data into memory 172/2374\n",
      "2023-04-05 20:54:03,066 [MainThread  ] [INFO ]  Loading features sequence data into memory 173/2374\n",
      "2023-04-05 20:54:03,263 [MainThread  ] [INFO ]  Loading features sequence data into memory 174/2374\n",
      "2023-04-05 20:54:03,655 [MainThread  ] [INFO ]  Loading features sequence data into memory 175/2374\n",
      "2023-04-05 20:54:03,714 [MainThread  ] [INFO ]  Loading features sequence data into memory 176/2374\n",
      "2023-04-05 20:54:04,669 [MainThread  ] [INFO ]  Loading features sequence data into memory 177/2374\n",
      "2023-04-05 20:54:04,748 [MainThread  ] [INFO ]  Loading features sequence data into memory 178/2374\n",
      "2023-04-05 20:54:04,830 [MainThread  ] [INFO ]  Loading features sequence data into memory 179/2374\n",
      "2023-04-05 20:54:05,450 [MainThread  ] [INFO ]  Loading features sequence data into memory 180/2374\n",
      "2023-04-05 20:54:05,730 [MainThread  ] [INFO ]  Loading features sequence data into memory 181/2374\n",
      "2023-04-05 20:54:05,784 [MainThread  ] [INFO ]  Loading features sequence data into memory 182/2374\n",
      "2023-04-05 20:54:07,403 [MainThread  ] [INFO ]  Loading features sequence data into memory 183/2374\n",
      "2023-04-05 20:54:08,441 [MainThread  ] [INFO ]  Loading features sequence data into memory 184/2374\n",
      "2023-04-05 20:54:09,381 [MainThread  ] [INFO ]  Loading features sequence data into memory 185/2374\n",
      "2023-04-05 20:54:09,463 [MainThread  ] [INFO ]  Loading features sequence data into memory 186/2374\n",
      "2023-04-05 20:54:09,576 [MainThread  ] [INFO ]  Loading features sequence data into memory 187/2374\n",
      "2023-04-05 20:54:09,640 [MainThread  ] [INFO ]  Loading features sequence data into memory 188/2374\n",
      "2023-04-05 20:54:10,204 [MainThread  ] [INFO ]  Loading features sequence data into memory 189/2374\n",
      "2023-04-05 20:54:10,309 [MainThread  ] [INFO ]  Loading features sequence data into memory 190/2374\n",
      "2023-04-05 20:54:10,571 [MainThread  ] [INFO ]  Loading features sequence data into memory 191/2374\n",
      "2023-04-05 20:54:10,704 [MainThread  ] [INFO ]  Loading features sequence data into memory 192/2374\n",
      "2023-04-05 20:54:10,761 [MainThread  ] [INFO ]  Loading features sequence data into memory 193/2374\n",
      "2023-04-05 20:54:10,852 [MainThread  ] [INFO ]  Loading features sequence data into memory 194/2374\n",
      "2023-04-05 20:54:11,069 [MainThread  ] [INFO ]  Loading features sequence data into memory 195/2374\n",
      "2023-04-05 20:54:11,227 [MainThread  ] [INFO ]  Loading features sequence data into memory 196/2374\n",
      "2023-04-05 20:54:11,401 [MainThread  ] [INFO ]  Loading features sequence data into memory 197/2374\n",
      "2023-04-05 20:54:11,451 [MainThread  ] [INFO ]  Loading features sequence data into memory 198/2374\n",
      "2023-04-05 20:54:11,623 [MainThread  ] [INFO ]  Loading features sequence data into memory 199/2374\n",
      "2023-04-05 20:54:11,790 [MainThread  ] [INFO ]  Loading features sequence data into memory 200/2374\n",
      "2023-04-05 20:54:11,984 [MainThread  ] [INFO ]  Loading features sequence data into memory 201/2374\n",
      "2023-04-05 20:54:12,062 [MainThread  ] [INFO ]  Loading features sequence data into memory 202/2374\n",
      "2023-04-05 20:54:12,115 [MainThread  ] [INFO ]  Loading features sequence data into memory 203/2374\n",
      "2023-04-05 20:54:12,301 [MainThread  ] [INFO ]  Loading features sequence data into memory 204/2374\n",
      "2023-04-05 20:54:12,518 [MainThread  ] [INFO ]  Loading features sequence data into memory 205/2374\n",
      "2023-04-05 20:54:13,502 [MainThread  ] [INFO ]  Loading features sequence data into memory 206/2374\n",
      "2023-04-05 20:54:13,558 [MainThread  ] [INFO ]  Loading features sequence data into memory 207/2374\n",
      "2023-04-05 20:54:13,639 [MainThread  ] [INFO ]  Loading features sequence data into memory 208/2374\n",
      "2023-04-05 20:54:13,725 [MainThread  ] [INFO ]  Loading features sequence data into memory 209/2374\n",
      "2023-04-05 20:54:13,805 [MainThread  ] [INFO ]  Loading features sequence data into memory 210/2374\n",
      "2023-04-05 20:54:13,859 [MainThread  ] [INFO ]  Loading features sequence data into memory 211/2374\n",
      "2023-04-05 20:54:13,930 [MainThread  ] [INFO ]  Loading features sequence data into memory 212/2374\n",
      "2023-04-05 20:54:14,058 [MainThread  ] [INFO ]  Loading features sequence data into memory 213/2374\n",
      "2023-04-05 20:54:14,182 [MainThread  ] [INFO ]  Loading features sequence data into memory 214/2374\n",
      "2023-04-05 20:54:15,000 [MainThread  ] [INFO ]  Loading features sequence data into memory 215/2374\n",
      "2023-04-05 20:54:15,056 [MainThread  ] [INFO ]  Loading features sequence data into memory 216/2374\n",
      "2023-04-05 20:54:15,695 [MainThread  ] [INFO ]  Loading features sequence data into memory 217/2374\n",
      "2023-04-05 20:54:15,811 [MainThread  ] [INFO ]  Loading features sequence data into memory 218/2374\n",
      "2023-04-05 20:54:16,555 [MainThread  ] [INFO ]  Loading features sequence data into memory 219/2374\n",
      "2023-04-05 20:54:16,980 [MainThread  ] [INFO ]  Loading features sequence data into memory 220/2374\n",
      "2023-04-05 20:54:17,081 [MainThread  ] [INFO ]  Loading features sequence data into memory 221/2374\n",
      "2023-04-05 20:54:17,424 [MainThread  ] [INFO ]  Loading features sequence data into memory 222/2374\n",
      "2023-04-05 20:54:17,669 [MainThread  ] [INFO ]  Loading features sequence data into memory 223/2374\n",
      "2023-04-05 20:54:18,087 [MainThread  ] [INFO ]  Loading features sequence data into memory 224/2374\n",
      "2023-04-05 20:54:18,278 [MainThread  ] [INFO ]  Loading features sequence data into memory 225/2374\n",
      "2023-04-05 20:54:18,351 [MainThread  ] [INFO ]  Loading features sequence data into memory 226/2374\n",
      "2023-04-05 20:54:18,657 [MainThread  ] [INFO ]  Loading features sequence data into memory 227/2374\n",
      "2023-04-05 20:54:19,082 [MainThread  ] [INFO ]  Loading features sequence data into memory 228/2374\n",
      "2023-04-05 20:54:19,141 [MainThread  ] [INFO ]  Loading features sequence data into memory 229/2374\n",
      "2023-04-05 20:54:19,203 [MainThread  ] [INFO ]  Loading features sequence data into memory 230/2374\n",
      "2023-04-05 20:54:20,026 [MainThread  ] [INFO ]  Loading features sequence data into memory 231/2374\n",
      "2023-04-05 20:54:20,128 [MainThread  ] [INFO ]  Loading features sequence data into memory 232/2374\n",
      "2023-04-05 20:54:20,486 [MainThread  ] [INFO ]  Loading features sequence data into memory 233/2374\n",
      "2023-04-05 20:54:20,751 [MainThread  ] [INFO ]  Loading features sequence data into memory 234/2374\n",
      "2023-04-05 20:54:20,905 [MainThread  ] [INFO ]  Loading features sequence data into memory 235/2374\n",
      "2023-04-05 20:54:21,032 [MainThread  ] [INFO ]  Loading features sequence data into memory 236/2374\n",
      "2023-04-05 20:54:21,263 [MainThread  ] [INFO ]  Loading features sequence data into memory 237/2374\n",
      "2023-04-05 20:54:21,317 [MainThread  ] [INFO ]  Loading features sequence data into memory 238/2374\n",
      "2023-04-05 20:54:21,640 [MainThread  ] [INFO ]  Loading features sequence data into memory 239/2374\n",
      "2023-04-05 20:54:21,891 [MainThread  ] [INFO ]  Loading features sequence data into memory 240/2374\n",
      "2023-04-05 20:54:22,075 [MainThread  ] [INFO ]  Loading features sequence data into memory 241/2374\n",
      "2023-04-05 20:54:22,470 [MainThread  ] [INFO ]  Loading features sequence data into memory 242/2374\n",
      "2023-04-05 20:54:23,561 [MainThread  ] [INFO ]  Loading features sequence data into memory 243/2374\n",
      "2023-04-05 20:54:23,927 [MainThread  ] [INFO ]  Loading features sequence data into memory 244/2374\n",
      "2023-04-05 20:54:24,087 [MainThread  ] [INFO ]  Loading features sequence data into memory 245/2374\n",
      "2023-04-05 20:54:24,143 [MainThread  ] [INFO ]  Loading features sequence data into memory 246/2374\n",
      "2023-04-05 20:54:24,225 [MainThread  ] [INFO ]  Loading features sequence data into memory 247/2374\n",
      "2023-04-05 20:54:24,275 [MainThread  ] [INFO ]  Loading features sequence data into memory 248/2374\n",
      "2023-04-05 20:54:24,458 [MainThread  ] [INFO ]  Loading features sequence data into memory 249/2374\n",
      "2023-04-05 20:54:24,932 [MainThread  ] [INFO ]  Loading features sequence data into memory 250/2374\n",
      "2023-04-05 20:54:25,497 [MainThread  ] [INFO ]  Loading features sequence data into memory 251/2374\n",
      "2023-04-05 20:54:26,425 [MainThread  ] [INFO ]  Loading features sequence data into memory 252/2374\n",
      "2023-04-05 20:54:26,526 [MainThread  ] [INFO ]  Loading features sequence data into memory 253/2374\n",
      "2023-04-05 20:54:28,976 [MainThread  ] [INFO ]  Loading features sequence data into memory 254/2374\n",
      "2023-04-05 20:54:34,395 [MainThread  ] [INFO ]  Loading features sequence data into memory 255/2374\n",
      "2023-04-05 20:54:34,587 [MainThread  ] [INFO ]  Loading features sequence data into memory 256/2374\n",
      "2023-04-05 20:54:34,736 [MainThread  ] [INFO ]  Loading features sequence data into memory 257/2374\n",
      "2023-04-05 20:54:34,832 [MainThread  ] [INFO ]  Loading features sequence data into memory 258/2374\n",
      "2023-04-05 20:54:34,941 [MainThread  ] [INFO ]  Loading features sequence data into memory 259/2374\n",
      "2023-04-05 20:54:35,363 [MainThread  ] [INFO ]  Loading features sequence data into memory 260/2374\n",
      "2023-04-05 20:54:35,417 [MainThread  ] [INFO ]  Loading features sequence data into memory 261/2374\n",
      "2023-04-05 20:54:36,805 [MainThread  ] [INFO ]  Loading features sequence data into memory 262/2374\n",
      "2023-04-05 20:54:36,897 [MainThread  ] [INFO ]  Loading features sequence data into memory 263/2374\n",
      "2023-04-05 20:54:36,953 [MainThread  ] [INFO ]  Loading features sequence data into memory 264/2374\n",
      "2023-04-05 20:54:37,463 [MainThread  ] [INFO ]  Loading features sequence data into memory 265/2374\n",
      "2023-04-05 20:54:38,113 [MainThread  ] [INFO ]  Loading features sequence data into memory 266/2374\n",
      "2023-04-05 20:54:39,392 [MainThread  ] [INFO ]  Loading features sequence data into memory 267/2374\n",
      "2023-04-05 20:54:39,447 [MainThread  ] [INFO ]  Loading features sequence data into memory 268/2374\n",
      "2023-04-05 20:54:39,532 [MainThread  ] [INFO ]  Loading features sequence data into memory 269/2374\n",
      "2023-04-05 20:54:39,594 [MainThread  ] [INFO ]  Loading features sequence data into memory 270/2374\n",
      "2023-04-05 20:54:39,907 [MainThread  ] [INFO ]  Loading features sequence data into memory 271/2374\n",
      "2023-04-05 20:54:41,607 [MainThread  ] [INFO ]  Loading features sequence data into memory 272/2374\n",
      "2023-04-05 20:54:42,117 [MainThread  ] [INFO ]  Loading features sequence data into memory 273/2374\n",
      "2023-04-05 20:54:42,861 [MainThread  ] [INFO ]  Loading features sequence data into memory 274/2374\n",
      "2023-04-05 20:54:43,218 [MainThread  ] [INFO ]  Loading features sequence data into memory 275/2374\n",
      "2023-04-05 20:54:43,280 [MainThread  ] [INFO ]  Loading features sequence data into memory 276/2374\n",
      "2023-04-05 20:54:43,338 [MainThread  ] [INFO ]  Loading features sequence data into memory 277/2374\n",
      "2023-04-05 20:54:43,672 [MainThread  ] [INFO ]  Loading features sequence data into memory 278/2374\n",
      "2023-04-05 20:54:44,004 [MainThread  ] [INFO ]  Loading features sequence data into memory 279/2374\n",
      "2023-04-05 20:54:44,347 [MainThread  ] [INFO ]  Loading features sequence data into memory 280/2374\n",
      "2023-04-05 20:54:44,782 [MainThread  ] [INFO ]  Loading features sequence data into memory 281/2374\n",
      "2023-04-05 20:54:45,007 [MainThread  ] [INFO ]  Loading features sequence data into memory 282/2374\n",
      "2023-04-05 20:54:45,392 [MainThread  ] [INFO ]  Loading features sequence data into memory 283/2374\n",
      "2023-04-05 20:54:45,516 [MainThread  ] [INFO ]  Loading features sequence data into memory 284/2374\n",
      "2023-04-05 20:54:45,575 [MainThread  ] [INFO ]  Loading features sequence data into memory 285/2374\n",
      "2023-04-05 20:54:46,216 [MainThread  ] [INFO ]  Loading features sequence data into memory 286/2374\n",
      "2023-04-05 20:55:08,169 [MainThread  ] [INFO ]  Loading features sequence data into memory 287/2374\n",
      "2023-04-05 20:55:09,246 [MainThread  ] [INFO ]  Loading features sequence data into memory 288/2374\n",
      "2023-04-05 20:55:09,819 [MainThread  ] [INFO ]  Loading features sequence data into memory 289/2374\n",
      "2023-04-05 20:55:09,877 [MainThread  ] [INFO ]  Loading features sequence data into memory 290/2374\n",
      "2023-04-05 20:55:10,154 [MainThread  ] [INFO ]  Loading features sequence data into memory 291/2374\n",
      "2023-04-05 20:55:10,214 [MainThread  ] [INFO ]  Loading features sequence data into memory 292/2374\n",
      "2023-04-05 20:55:10,650 [MainThread  ] [INFO ]  Loading features sequence data into memory 293/2374\n",
      "2023-04-05 20:55:10,708 [MainThread  ] [INFO ]  Loading features sequence data into memory 294/2374\n",
      "2023-04-05 20:55:11,142 [MainThread  ] [INFO ]  Loading features sequence data into memory 295/2374\n",
      "2023-04-05 20:55:11,415 [MainThread  ] [INFO ]  Loading features sequence data into memory 296/2374\n",
      "2023-04-05 20:55:11,627 [MainThread  ] [INFO ]  Loading features sequence data into memory 297/2374\n",
      "2023-04-05 20:55:12,257 [MainThread  ] [INFO ]  Loading features sequence data into memory 298/2374\n",
      "2023-04-05 20:55:14,085 [MainThread  ] [INFO ]  Loading features sequence data into memory 299/2374\n",
      "2023-04-05 20:55:15,319 [MainThread  ] [INFO ]  Loading features sequence data into memory 300/2374\n",
      "2023-04-05 20:55:15,571 [MainThread  ] [INFO ]  Loading features sequence data into memory 301/2374\n",
      "2023-04-05 20:55:15,676 [MainThread  ] [INFO ]  Loading features sequence data into memory 302/2374\n",
      "2023-04-05 20:56:02,685 [MainThread  ] [INFO ]  Loading features sequence data into memory 303/2374\n",
      "2023-04-05 20:56:05,464 [MainThread  ] [INFO ]  Loading features sequence data into memory 304/2374\n",
      "2023-04-05 20:56:05,803 [MainThread  ] [INFO ]  Loading features sequence data into memory 305/2374\n",
      "2023-04-05 20:56:06,050 [MainThread  ] [INFO ]  Loading features sequence data into memory 306/2374\n",
      "2023-04-05 20:56:06,996 [MainThread  ] [INFO ]  Loading features sequence data into memory 307/2374\n",
      "2023-04-05 20:56:07,239 [MainThread  ] [INFO ]  Loading features sequence data into memory 308/2374\n",
      "2023-04-05 20:56:07,478 [MainThread  ] [INFO ]  Loading features sequence data into memory 309/2374\n",
      "2023-04-05 20:56:07,891 [MainThread  ] [INFO ]  Loading features sequence data into memory 310/2374\n",
      "2023-04-05 20:56:08,530 [MainThread  ] [INFO ]  Loading features sequence data into memory 311/2374\n",
      "2023-04-05 20:56:08,597 [MainThread  ] [INFO ]  Loading features sequence data into memory 312/2374\n",
      "2023-04-05 20:56:08,756 [MainThread  ] [INFO ]  Loading features sequence data into memory 313/2374\n",
      "2023-04-05 20:56:08,812 [MainThread  ] [INFO ]  Loading features sequence data into memory 314/2374\n",
      "2023-04-05 20:56:09,106 [MainThread  ] [INFO ]  Loading features sequence data into memory 315/2374\n",
      "2023-04-05 20:56:09,282 [MainThread  ] [INFO ]  Loading features sequence data into memory 316/2374\n",
      "2023-04-05 20:56:10,359 [MainThread  ] [INFO ]  Loading features sequence data into memory 317/2374\n",
      "2023-04-05 20:56:10,414 [MainThread  ] [INFO ]  Loading features sequence data into memory 318/2374\n",
      "2023-04-05 20:56:10,505 [MainThread  ] [INFO ]  Loading features sequence data into memory 319/2374\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m be_data \u001b[39m=\u001b[39m Data(\n\u001b[1;32m      2\u001b[0m     sequence_length \u001b[39m=\u001b[39;49m experiment[\u001b[39m'\u001b[39;49m\u001b[39msequence_length\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m      3\u001b[0m     return_CNN_features \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m, \n\u001b[1;32m      4\u001b[0m     pretrained_model_name \u001b[39m=\u001b[39;49m experiment[\u001b[39m'\u001b[39;49m\u001b[39mpretrained_model_name\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m      5\u001b[0m     pooling \u001b[39m=\u001b[39;49m experiment[\u001b[39m'\u001b[39;49m\u001b[39mpooling\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m      6\u001b[0m     frame_size \u001b[39m=\u001b[39;49m experiment[\u001b[39m'\u001b[39;49m\u001b[39mframe_size\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m      7\u001b[0m     custom_model_name\u001b[39m=\u001b[39;49m experiment[\u001b[39m'\u001b[39;49m\u001b[39mcustom_model_name\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m      8\u001b[0m     return_generator \u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m      9\u001b[0m     _bed \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m )\n",
      "Cell \u001b[0;32mIn[21], line 121\u001b[0m, in \u001b[0;36mData.__init__\u001b[0;34m(self, sequence_length, return_CNN_features, pretrained_model_name, pooling, frame_size, custom_model_name, _bed, verbose, return_generator)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msequence_length, \u001b[39mlen\u001b[39m(features) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m    120\u001b[0m     x\u001b[39m.\u001b[39mappend(features[i\u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msequence_length:i])\n\u001b[0;32m--> 121\u001b[0m x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49marray(x)\n\u001b[1;32m    124\u001b[0m \u001b[39m# temp lists to store sequences\u001b[39;00m\n\u001b[1;32m    125\u001b[0m be_labels \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabels\u001b[39m.\u001b[39mloc[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabels\u001b[39m.\u001b[39mboarding_event \u001b[39m==\u001b[39m be_name]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "be_data = Data(\n",
    "    sequence_length = experiment['sequence_length'],\n",
    "    return_CNN_features = True, \n",
    "    pretrained_model_name = experiment['pretrained_model_name'],\n",
    "    pooling = experiment['pooling'],\n",
    "    frame_size = experiment['frame_size'],\n",
    "    custom_model_name= experiment['custom_model_name'],\n",
    "    return_generator = False,\n",
    "    _bed = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete existing results\n",
    "if os.path.exists(DNN_lib_path + '/models/' + str(experiment[\"model_id\"]) + '/results.json'):\n",
    "    rmtree(DNN_lib_path + '/models/' + str(experiment[\"model_id\"]) + '/')\n",
    "# create models folder if doesn't exist\n",
    "if not os.path.exists(DNN_lib_path + '/models/'):\n",
    "    os.makedirs(DNN_lib_path + '/models/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-03 18:47:12,973 [MainThread  ] [INFO ]  Model folder exists but no results found - potential error in previous model training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1   XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "{'architecture': 'video_mlp_concat', 'dropout': 0.2, 'layer_1_size': 256, 'layer_2_size': 512, 'layer_3_size': 256, 'model_id': 1, 'pooling': 'max', 'pretrained_model_name': 'resnet50', 'custom_model_name': 'ResNet50_pop_grids', 'path_features': '/cache/ResNet50_pop_grids', 'sequence_length': 20, 'sequence_model': 'LSTM', 'sequence_model_layers': 3, 'frame_size': (32, 32)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-03 18:47:13.196499: E tensorflow/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2023-04-03 18:47:13.197606: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: pop-os\n",
      "2023-04-03 18:47:13.197621: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: pop-os\n",
      "2023-04-03 18:47:13.198091: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 525.85.5\n",
      "2023-04-03 18:47:13.199057: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 525.85.5\n",
      "2023-04-03 18:47:13.199068: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 525.85.5\n",
      "2023-04-03 18:47:13.210678: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "print(str(experiment[\"model_id\"]) + \"   \" + \"X\"*60)\n",
    "print(experiment)\n",
    "\n",
    "architecture = Architecture(model_id = experiment['model_id'], \n",
    "                            architecture = 'video_lrcnn_frozen', \n",
    "                            sequence_length = experiment['sequence_length'], \n",
    "                            pretrained_model_name = experiment['pretrained_model_name'],\n",
    "                            custom_model_name = experiment['custom_model_name'],\n",
    "                            pooling = experiment['pooling'],\n",
    "                            sequence_model = experiment['sequence_model'],\n",
    "                            sequence_model_layers = experiment['sequence_model_layers'],\n",
    "                            layer_1_size = experiment['layer_1_size'],\n",
    "                            layer_2_size = experiment['layer_2_size'],\n",
    "                            layer_3_size = experiment['layer_3_size'],\n",
    "                            dropout = experiment['dropout'],\n",
    "                            _bed = True,\n",
    "                            verbose=True,\n",
    "                            data = be_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-03 18:47:14.905027: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 5337907200 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.82265, saving model to /home/tiesbarendse/Documents/00_Uni/22_23/pap/Deep-Neural-Networks-for-Video-Classification/notebooks/../models/1/model_round_1.h5\n",
      "\n",
      "Epoch 2: val_accuracy improved from 0.82265 to 0.83425, saving model to /home/tiesbarendse/Documents/00_Uni/22_23/pap/Deep-Neural-Networks-for-Video-Classification/notebooks/../models/1/model_round_1.h5\n",
      "\n",
      "Epoch 3: val_accuracy improved from 0.83425 to 0.83702, saving model to /home/tiesbarendse/Documents/00_Uni/22_23/pap/Deep-Neural-Networks-for-Video-Classification/notebooks/../models/1/model_round_1.h5\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.83702\n",
      "\n",
      "Epoch 5: val_accuracy did not improve from 0.83702\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 0.83702\n",
      "Epoch 6: early stopping\n",
      "H1 {'loss': [0.22107233107089996, 0.19697020947933197, 0.19114236533641815, 0.18833491206169128, 0.18994078040122986, 0.18175280094146729], 'accuracy': [0.7420810461044312, 0.7761203050613403, 0.7814303040504456, 0.7846531867980957, 0.7841620445251465, 0.792879045009613], 'val_loss': [0.15678101778030396, 0.15201349556446075, 0.15191717445850372, 0.1723202019929886, 0.17058387398719788, 0.18619711697101593], 'val_accuracy': [0.8226519227027893, 0.8342541456222534, 0.8370165824890137, 0.7977900505065918, 0.8077347874641418, 0.779558002948761]}\n",
      "stopped_epoch1 3\n",
      "6\n",
      "0.7977900505065918\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "architecture.train_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "8f9fd7e5cd0ee174f389b9d7efcf5e4e8d178ce255061fb4046125c712618101"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
