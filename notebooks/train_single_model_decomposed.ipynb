{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T17:14:17.264442Z",
     "start_time": "2020-05-14T17:14:17.250090Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# whether to log each feature and sequence status\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T17:14:18.583218Z",
     "start_time": "2020-05-14T17:14:17.657048Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-03 18:43:41.272705: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-03 18:43:42.024863: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /app/lib\n",
      "2023-04-03 18:43:42.024917: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-04-03 18:43:42.100090: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-04-03 18:43:43.388318: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /app/lib\n",
      "2023-04-03 18:43:43.388465: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /app/lib\n",
      "2023-04-03 18:43:43.388474: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.utils import shuffle\n",
    "import sys\n",
    "from shutil import rmtree\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T17:14:18.993048Z",
     "start_time": "2020-05-14T17:14:18.988996Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "__file__ = os.path.abspath('helper_precomputing_CNN_features.ipynb')\n",
    "DNN_lib_path = Path(__file__).parents[1].__str__()\n",
    "path_data = '/media/tiesbarendse/DATA/be_ts/'\n",
    "path_cache = DNN_lib_path + '/cache/'\n",
    "\n",
    "custom_model_name = 'ResNet50_pop_grids'\n",
    "path_features = path_cache + '/features/' + custom_model_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T17:14:19.880582Z",
     "start_time": "2020-05-14T17:14:19.867630Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup logging\n",
    "# any explicit log messages or uncaught errors to stdout and file /logs.log\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(threadName)-12.12s] [%(levelname)-5.5s]  %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(f\"{DNN_lib_path}/logs_{custom_model_name}_training.log\"),\n",
    "        logging.StreamHandler()\n",
    "    ])\n",
    "# init logger\n",
    "logger = logging.getLogger()\n",
    "# make logger aware of any uncaught exceptions\n",
    "def handle_exception(exc_type, exc_value, exc_traceback):\n",
    "    if issubclass(exc_type, KeyboardInterrupt):\n",
    "        sys.__excepthook__(exc_type, exc_value, exc_traceback)\n",
    "        return\n",
    "\n",
    "    logger.error(\"Uncaught exception\", exc_info=(exc_type, exc_value, exc_traceback))\n",
    "sys.excepthook = handle_exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T17:14:24.947193Z",
     "start_time": "2020-05-14T17:14:20.448078Z"
    }
   },
   "outputs": [],
   "source": [
    "from deepvideoclassification.architectures import Architecture\n",
    "from deepvideoclassification.data import Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Data Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video</th>\n",
       "      <th>frame</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trajs_2017-03-01_Ut_3040_door_4</td>\n",
       "      <td>trajs_2017-03-01_Ut_3040_door_4-0000.npy</td>\n",
       "      <td>pre-deboarding</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trajs_2017-03-01_Ut_3040_door_4</td>\n",
       "      <td>trajs_2017-03-01_Ut_3040_door_4-0001.npy</td>\n",
       "      <td>pre-deboarding</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>trajs_2017-03-01_Ut_3040_door_4</td>\n",
       "      <td>trajs_2017-03-01_Ut_3040_door_4-0002.npy</td>\n",
       "      <td>pre-deboarding</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trajs_2017-03-01_Ut_3040_door_4</td>\n",
       "      <td>trajs_2017-03-01_Ut_3040_door_4-0003.npy</td>\n",
       "      <td>pre-deboarding</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>trajs_2017-03-01_Ut_3040_door_4</td>\n",
       "      <td>trajs_2017-03-01_Ut_3040_door_4-0004.npy</td>\n",
       "      <td>pre-deboarding</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>trajs_2018-06-07_Ut_3076_door_3</td>\n",
       "      <td>trajs_2018-06-07_Ut_3076_door_3-0195.npy</td>\n",
       "      <td>post-boarding</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>trajs_2018-06-07_Ut_3076_door_3</td>\n",
       "      <td>trajs_2018-06-07_Ut_3076_door_3-0196.npy</td>\n",
       "      <td>post-boarding</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>trajs_2018-06-07_Ut_3076_door_3</td>\n",
       "      <td>trajs_2018-06-07_Ut_3076_door_3-0197.npy</td>\n",
       "      <td>post-boarding</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>trajs_2018-06-07_Ut_3076_door_3</td>\n",
       "      <td>trajs_2018-06-07_Ut_3076_door_3-0198.npy</td>\n",
       "      <td>post-boarding</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>trajs_2018-06-07_Ut_3076_door_3</td>\n",
       "      <td>trajs_2018-06-07_Ut_3076_door_3-0199.npy</td>\n",
       "      <td>post-boarding</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 video  \\\n",
       "0      trajs_2017-03-01_Ut_3040_door_4   \n",
       "1      trajs_2017-03-01_Ut_3040_door_4   \n",
       "2      trajs_2017-03-01_Ut_3040_door_4   \n",
       "3      trajs_2017-03-01_Ut_3040_door_4   \n",
       "4      trajs_2017-03-01_Ut_3040_door_4   \n",
       "...                                ...   \n",
       "39995  trajs_2018-06-07_Ut_3076_door_3   \n",
       "39996  trajs_2018-06-07_Ut_3076_door_3   \n",
       "39997  trajs_2018-06-07_Ut_3076_door_3   \n",
       "39998  trajs_2018-06-07_Ut_3076_door_3   \n",
       "39999  trajs_2018-06-07_Ut_3076_door_3   \n",
       "\n",
       "                                          frame           label  split  \n",
       "0      trajs_2017-03-01_Ut_3040_door_4-0000.npy  pre-deboarding  valid  \n",
       "1      trajs_2017-03-01_Ut_3040_door_4-0001.npy  pre-deboarding  valid  \n",
       "2      trajs_2017-03-01_Ut_3040_door_4-0002.npy  pre-deboarding  valid  \n",
       "3      trajs_2017-03-01_Ut_3040_door_4-0003.npy  pre-deboarding  valid  \n",
       "4      trajs_2017-03-01_Ut_3040_door_4-0004.npy  pre-deboarding  valid  \n",
       "...                                         ...             ...    ...  \n",
       "39995  trajs_2018-06-07_Ut_3076_door_3-0195.npy   post-boarding  train  \n",
       "39996  trajs_2018-06-07_Ut_3076_door_3-0196.npy   post-boarding  train  \n",
       "39997  trajs_2018-06-07_Ut_3076_door_3-0197.npy   post-boarding  train  \n",
       "39998  trajs_2018-06-07_Ut_3076_door_3-0198.npy   post-boarding  train  \n",
       "39999  trajs_2018-06-07_Ut_3076_door_3-0199.npy   post-boarding  train  \n",
       "\n",
       "[40000 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df = pd.read_csv(path_data + 'labels.csv', usecols=['video','frame','label','split']).sort_values(['video', 'frame'])\n",
    "label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video</th>\n",
       "      <th>frame</th>\n",
       "      <th>split</th>\n",
       "      <th>label_boarding</th>\n",
       "      <th>label_deboarding</th>\n",
       "      <th>label_phase-change</th>\n",
       "      <th>label_post-boarding</th>\n",
       "      <th>label_pre-deboarding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trajs_2017-03-01_Ut_3040_door_4</td>\n",
       "      <td>trajs_2017-03-01_Ut_3040_door_4-0000.npy</td>\n",
       "      <td>valid</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trajs_2017-03-01_Ut_3040_door_4</td>\n",
       "      <td>trajs_2017-03-01_Ut_3040_door_4-0001.npy</td>\n",
       "      <td>valid</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>trajs_2017-03-01_Ut_3040_door_4</td>\n",
       "      <td>trajs_2017-03-01_Ut_3040_door_4-0002.npy</td>\n",
       "      <td>valid</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trajs_2017-03-01_Ut_3040_door_4</td>\n",
       "      <td>trajs_2017-03-01_Ut_3040_door_4-0003.npy</td>\n",
       "      <td>valid</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>trajs_2017-03-01_Ut_3040_door_4</td>\n",
       "      <td>trajs_2017-03-01_Ut_3040_door_4-0004.npy</td>\n",
       "      <td>valid</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>trajs_2018-06-07_Ut_3076_door_3</td>\n",
       "      <td>trajs_2018-06-07_Ut_3076_door_3-0195.npy</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>trajs_2018-06-07_Ut_3076_door_3</td>\n",
       "      <td>trajs_2018-06-07_Ut_3076_door_3-0196.npy</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>trajs_2018-06-07_Ut_3076_door_3</td>\n",
       "      <td>trajs_2018-06-07_Ut_3076_door_3-0197.npy</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>trajs_2018-06-07_Ut_3076_door_3</td>\n",
       "      <td>trajs_2018-06-07_Ut_3076_door_3-0198.npy</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>trajs_2018-06-07_Ut_3076_door_3</td>\n",
       "      <td>trajs_2018-06-07_Ut_3076_door_3-0199.npy</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 video  \\\n",
       "0      trajs_2017-03-01_Ut_3040_door_4   \n",
       "1      trajs_2017-03-01_Ut_3040_door_4   \n",
       "2      trajs_2017-03-01_Ut_3040_door_4   \n",
       "3      trajs_2017-03-01_Ut_3040_door_4   \n",
       "4      trajs_2017-03-01_Ut_3040_door_4   \n",
       "...                                ...   \n",
       "39995  trajs_2018-06-07_Ut_3076_door_3   \n",
       "39996  trajs_2018-06-07_Ut_3076_door_3   \n",
       "39997  trajs_2018-06-07_Ut_3076_door_3   \n",
       "39998  trajs_2018-06-07_Ut_3076_door_3   \n",
       "39999  trajs_2018-06-07_Ut_3076_door_3   \n",
       "\n",
       "                                          frame  split  label_boarding  \\\n",
       "0      trajs_2017-03-01_Ut_3040_door_4-0000.npy  valid               0   \n",
       "1      trajs_2017-03-01_Ut_3040_door_4-0001.npy  valid               0   \n",
       "2      trajs_2017-03-01_Ut_3040_door_4-0002.npy  valid               0   \n",
       "3      trajs_2017-03-01_Ut_3040_door_4-0003.npy  valid               0   \n",
       "4      trajs_2017-03-01_Ut_3040_door_4-0004.npy  valid               0   \n",
       "...                                         ...    ...             ...   \n",
       "39995  trajs_2018-06-07_Ut_3076_door_3-0195.npy  train               0   \n",
       "39996  trajs_2018-06-07_Ut_3076_door_3-0196.npy  train               0   \n",
       "39997  trajs_2018-06-07_Ut_3076_door_3-0197.npy  train               0   \n",
       "39998  trajs_2018-06-07_Ut_3076_door_3-0198.npy  train               0   \n",
       "39999  trajs_2018-06-07_Ut_3076_door_3-0199.npy  train               0   \n",
       "\n",
       "       label_deboarding  label_phase-change  label_post-boarding  \\\n",
       "0                     0                   0                    0   \n",
       "1                     0                   0                    0   \n",
       "2                     0                   0                    0   \n",
       "3                     0                   0                    0   \n",
       "4                     0                   0                    0   \n",
       "...                 ...                 ...                  ...   \n",
       "39995                 0                   0                    1   \n",
       "39996                 0                   0                    1   \n",
       "39997                 0                   0                    1   \n",
       "39998                 0                   0                    1   \n",
       "39999                 0                   0                    1   \n",
       "\n",
       "       label_pre-deboarding  \n",
       "0                         1  \n",
       "1                         1  \n",
       "2                         1  \n",
       "3                         1  \n",
       "4                         1  \n",
       "...                     ...  \n",
       "39995                     0  \n",
       "39996                     0  \n",
       "39997                     0  \n",
       "39998                     0  \n",
       "39999                     0  \n",
       "\n",
       "[40000 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_dummied = pd.get_dummies(label_df, columns=['label'])\n",
    "labels_dummied \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerization_dict = dict({\n",
    "    None : 4,\n",
    "    np.nan: 4, \n",
    "    'pre-deboarding': 0,\n",
    "    'deboarding': 1,\n",
    "    'phase-change': 2,\n",
    "    'boarding': 3,\n",
    "    'post-boarding': 0\n",
    "})\n",
    "\n",
    "class Data(object):\n",
    "\n",
    "    def __init__(self, sequence_length,\n",
    "                 return_CNN_features=True,\n",
    "                 pretrained_model_name=None,\n",
    "                 pooling=None,\n",
    "                 frame_size=None,\n",
    "                 custom_model_name=None,\n",
    "                 _bed=False,\n",
    "                 verbose=True,\n",
    "                 return_generator = False):\n",
    "        \"\"\"\n",
    "        Data object constructor\n",
    "        \n",
    "        \n",
    "        :sequence_length: number of frames in sequence to be returned by Data object\n",
    "        :return_CNN_features: whether to return precomputed features or return frames (or sequences of features/frames if sequence_length>1)\n",
    "\n",
    "        :return_features: if True then return features (or sequences of feature) from pretrained model, if False then return frames (or sequences of frames)        \n",
    "        :pretrained_model_name: name of pretrained model (or None if not using pretrained model e.g. for 3D-CNN)\n",
    "        :pooling: name of pooling variant (or None if not using pretrained model e.g. for 3D-CNN)\n",
    "        :frame_size: size that frames are resized to (this is looked up for pretrained models)\n",
    "        :aug3mentation: whether to apply data augmentation (horizontal flips)\n",
    "        :oversampling: whether to apply oversampling to create class balance\n",
    "        \n",
    "        :model_weights_path: path to custom model weights if we want to load CNN model we've fine-tuned to produce features (e.g. for LRCNN)\n",
    "        :custom_model_name: custom output name to append to pretrained model name\n",
    "        \n",
    "        :return_generator: if True and sequence_length > 1 and return_CNN_features == False, then do not return dataset, instead construct h5 file with sequences for each split and return generator that samples from that (dataset of sequecne frames too big to load into memory)\n",
    "        :batch_size: size of batches that generator must return\n",
    "        \n",
    "        :verbose: whether to log details\n",
    "        \n",
    "        Notes: \n",
    "        * if pretrained_model_name != None and return_CNN_features=False then will first apply preprocessor to frames (or frame sequences)\n",
    "        * if return_generator = True and sequence_length > 1 and return_CNN_features == False, large h5 files will be created in cache before returning generator\n",
    "        \"\"\"\n",
    "\n",
    "        # required params\n",
    "        self.sequence_length = sequence_length\n",
    "        self.frame_size = frame_size\n",
    "\n",
    "        # optional params\n",
    "        self.pretrained_model_name = pretrained_model_name\n",
    "        self.pooling = pooling\n",
    "        self.return_CNN_features = return_CNN_features\n",
    "        self.custom_model_name = custom_model_name\n",
    "        self.return_generator = return_generator\n",
    "\n",
    "        self.bed = _bed\n",
    "        self.frame_size = frame_size\n",
    "\n",
    "        self.verbose = verbose\n",
    "\n",
    "        self.x_train = []\n",
    "        self.y_train = []\n",
    "        #\n",
    "        self.x_valid = []\n",
    "        self.y_valid = []\n",
    "        #\n",
    "        self.x_test = []\n",
    "        self.y_test = []\n",
    "\n",
    "        ################\n",
    "        ### Prepare data\n",
    "        ################\n",
    "\n",
    "        #Label loading\n",
    "        self.labels = pd.read_csv(path_data + 'labels.csv', usecols=['video','frame','label','split']).sort_values(['video', 'frame'])\n",
    "        \n",
    "        # get label columns list and build label map dict\n",
    "        label_columns = []\n",
    "        label_map = {}\n",
    "        label_map_idx = 0\n",
    "        for i, col in enumerate(labels_dummied.columns):\n",
    "            if col[:6] == 'label_':\n",
    "                label_columns.append(col)\n",
    "                label_map[label_map_idx] = col\n",
    "                label_map_idx+=1\n",
    "\n",
    "        self.label_map = label_map\n",
    "\n",
    "        # get video paths\n",
    "        self.path_videos = [f\"{path_data}/{video}\" for video in os.listdir(path_data) if os.path.isdir(f\"{path_data}/{video}\")]\n",
    "\n",
    "        # check that there is 1 frame file for each label file and raise error if they don't match\n",
    "        path_frames = []\n",
    "        for folder, subs, files in os.walk(path_data):\n",
    "            for filename in files:\n",
    "                if self.bed & (filename[-4:].lower() == '.npy'):\n",
    "                    path_frames.append(os.path.abspath(\n",
    "                        os.path.join(folder, filename)))\n",
    "\n",
    "                if filename[-4:].lower() == '.jpg' or filename[-4:].lower() == 'jpeg' or filename[-4:].lower() == '.png':\n",
    "                    path_frames.append(os.path.abspath(\n",
    "                        os.path.join(folder, filename)))\n",
    "\n",
    "        if len(path_frames) != len(self.labels):\n",
    "            error_msg = 'IMPORTANT ERROR: Number of frames ({}) in /data/ video folders needs to match number of labels ({}) in labels.csv - use notebooks/helper_check_frames_against_labels.ipynb to investigate... Note, only labels.csv and the frames you want to use (in video subfolders) should be in /data/'.format(\n",
    "                len(path_frames), len(self.labels))\n",
    "            logger.info(error_msg)\n",
    "            raise ValueError(error_msg)\n",
    "\n",
    "        # pull number of classes from labels shape\n",
    "        self.num_classes = self.labels['label'].nunique()\n",
    "\n",
    "        # create dict mapping video to train/valid/test split assignment\n",
    "        video_splits = self.labels[['video', 'split']].drop_duplicates()\n",
    "        video_splits.set_index(\"video\", inplace=True)\n",
    "        video_splits = video_splits.to_dict()['split']\n",
    "        self.video_splits = video_splits\n",
    "\n",
    "        # precompute resized frames (won't recompute if already resized)\n",
    "        #resize_frames(self.frame_size, _bed = self.bed, _verbose = self.verbose)\n",
    "\n",
    "        ###################################\n",
    "        ### load features / build sequences\n",
    "        ###################################\n",
    "\n",
    "        # load features/frames from all videos and concat into big array for each of train, valid and test\n",
    "        assert self.return_CNN_features\n",
    "\n",
    "        if verbose:\n",
    "            logging.info(\n",
    "                \"Loading features sequence data into memory [may take a few minutes]\")\n",
    "\n",
    "        #####################\n",
    "        ### feature sequences\n",
    "        #####################\n",
    "\n",
    "        path_features = path_cache + 'features/' + self.custom_model_name\n",
    "        path_labels = path_cache + 'labels/'\n",
    "        \n",
    "        bes_names = [be for be in os.listdir(path_data) if os.path.isdir(f\"{path_data}/{be}\")]\n",
    "\n",
    "        # loop over all vids and load precomputed features into memory as sequences\n",
    "        for c, be_name in enumerate(bes_names):\n",
    "\n",
    "            path_be = f'{path_data}/{be_name}'\n",
    "\n",
    "            if verbose:\n",
    "                logging.info(\"Loading features sequence data into memory {}/{}\".format(c+1,len(bes_names)))\n",
    "\n",
    "            ### create sequence: features\n",
    "            # load precomputed features\n",
    "            features = np.load(f\"{path_features}/{be_name}.npy\")\n",
    "            # build sequences\n",
    "            x = []\n",
    "            for i in range(self.sequence_length, len(features) + 1):\n",
    "                x.append(features[i-self.sequence_length:i])\n",
    "            x = np.array(x)\n",
    "            \n",
    "\n",
    "            # temp lists to store sequences\n",
    "            be_labels = self.labels[self.labels.video == be_name]\n",
    "            y = []\n",
    "            for i in range(self.sequence_length, len(be_labels) + 1):\n",
    "                label = be_labels.label.iloc[i-1]\n",
    "                if (label is None) or (label == np.nan):\n",
    "                    label = 'nan'\n",
    "                y.append(label)\n",
    "            y = np.array(list(map(numerization_dict.get, y)))\n",
    "            y = to_categorical(y, num_classes=5)\n",
    "\n",
    "            assert len(x) == len(y), f'Length of features ({len(x)}) does not match length of labels ({len(y)})'\n",
    "\n",
    "            ### build output\n",
    "            if self.video_splits[be_name] == \"train\":\n",
    "                self.x_train.append(x)\n",
    "                self.y_train.append(y)\n",
    "            if self.video_splits[be_name] == \"valid\":\n",
    "                self.x_valid.append(x)\n",
    "                self.y_valid.append(y)\n",
    "            if self.video_splits[be_name] == \"test\":\n",
    "                self.x_test.append(x)\n",
    "                self.y_test.append(y)\n",
    "\n",
    "        #################################\n",
    "        ### get file paths for each split\n",
    "        #################################\n",
    "        #\n",
    "        # Note: only makes sense for sequence_length = 1\n",
    "\n",
    "        # get file paths: train\n",
    "        dflab = self.labels[self.labels['split'] == 'train']\n",
    "        self.paths_train = list(\n",
    "            path_data + dflab['video'] + \"/\" + dflab['frame'])\n",
    "\n",
    "        # get file paths: valid\n",
    "        dflab = self.labels[self.labels['split'] == 'valid']\n",
    "        self.paths_valid = list(\n",
    "            path_data + dflab['video'] + \"/\" + dflab['frame'])\n",
    "\n",
    "        # get file paths: test\n",
    "        dflab = self.labels[self.labels['split'] == 'test']\n",
    "        self.paths_test = list(\n",
    "            path_data + dflab['video'] + \"/\" + dflab['frame'])\n",
    "\n",
    "        #################################################\n",
    "        ### reshape list outputs (if not using generator)\n",
    "        #################################################\n",
    "\n",
    "        ## e.g. (9846, 224, 224, 3) for frames [return_CNN_features=True]\n",
    "        ## or  (9846, 512) for features [return_CNN_features=False]\n",
    "        self.x_train = np.concatenate(self.x_train, axis=0)\n",
    "        self.y_train = np.concatenate(self.y_train, axis=0)\n",
    "        self.x_valid = np.concatenate(self.x_valid, axis=0)\n",
    "        self.y_valid = np.concatenate(self.y_valid, axis=0)\n",
    "        self.x_test = np.concatenate(self.x_test, axis=0)\n",
    "        self.y_test = np.concatenate(self.y_test, axis=0)\n",
    "\n",
    "        self.total_rows_train = len(self.x_train)\n",
    "        self.total_rows_valid = len(self.x_valid)\n",
    "        self.total_rows_test = len(self.x_test)\n",
    "\n",
    "        # shuffle train and validation set\n",
    "        self.x_train, self.y_train = shuffle(self.x_train, self.y_train)\n",
    "        self.x_valid, self.y_valid = shuffle(self.x_valid, self.y_valid)\n",
    "\n",
    "        # update progress\n",
    "        if self.verbose:\n",
    "            print(\"Done initializing data with #samples: train={}, valid={}, test={}\".format(\n",
    "                self.total_rows_train, self.total_rows_valid, self.total_rows_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = {\n",
    "    'architecture': 'video_mlp_concat',\n",
    "    'dropout': 0.2,\n",
    "    'layer_1_size': 256,\n",
    "    'layer_2_size': 512,\n",
    "    'layer_3_size': 256,\n",
    "    'model_id': 1,\n",
    "    'pooling': 'max',\n",
    "    'pretrained_model_name': 'resnet50',\n",
    "    'custom_model_name': custom_model_name,\n",
    "    'path_features': f'/cache/{custom_model_name}',\n",
    "    'sequence_length': 20,\n",
    "    'sequence_model': \"LSTM\",\n",
    "    'sequence_model_layers': 3,\n",
    "    'frame_size': (32, 32)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T17:15:28.835943Z",
     "start_time": "2020-05-14T17:14:48.938251Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-03 18:43:49,601 [MainThread  ] [INFO ]  Loading features sequence data into memory [may take a few minutes]\n",
      "2023-04-03 18:43:49,619 [MainThread  ] [INFO ]  Loading features sequence data into memory 1/200\n",
      "2023-04-03 18:43:49,637 [MainThread  ] [INFO ]  Loading features sequence data into memory 2/200\n",
      "2023-04-03 18:43:49,658 [MainThread  ] [INFO ]  Loading features sequence data into memory 3/200\n",
      "2023-04-03 18:43:49,676 [MainThread  ] [INFO ]  Loading features sequence data into memory 4/200\n",
      "2023-04-03 18:43:49,694 [MainThread  ] [INFO ]  Loading features sequence data into memory 5/200\n",
      "2023-04-03 18:43:49,711 [MainThread  ] [INFO ]  Loading features sequence data into memory 6/200\n",
      "2023-04-03 18:43:49,729 [MainThread  ] [INFO ]  Loading features sequence data into memory 7/200\n",
      "2023-04-03 18:43:49,747 [MainThread  ] [INFO ]  Loading features sequence data into memory 8/200\n",
      "2023-04-03 18:43:49,766 [MainThread  ] [INFO ]  Loading features sequence data into memory 9/200\n",
      "2023-04-03 18:43:49,784 [MainThread  ] [INFO ]  Loading features sequence data into memory 10/200\n",
      "2023-04-03 18:43:49,802 [MainThread  ] [INFO ]  Loading features sequence data into memory 11/200\n",
      "2023-04-03 18:43:49,819 [MainThread  ] [INFO ]  Loading features sequence data into memory 12/200\n",
      "2023-04-03 18:43:49,837 [MainThread  ] [INFO ]  Loading features sequence data into memory 13/200\n",
      "2023-04-03 18:43:49,855 [MainThread  ] [INFO ]  Loading features sequence data into memory 14/200\n",
      "2023-04-03 18:43:49,871 [MainThread  ] [INFO ]  Loading features sequence data into memory 15/200\n",
      "2023-04-03 18:43:49,890 [MainThread  ] [INFO ]  Loading features sequence data into memory 16/200\n",
      "2023-04-03 18:43:49,906 [MainThread  ] [INFO ]  Loading features sequence data into memory 17/200\n",
      "2023-04-03 18:43:49,922 [MainThread  ] [INFO ]  Loading features sequence data into memory 18/200\n",
      "2023-04-03 18:43:49,940 [MainThread  ] [INFO ]  Loading features sequence data into memory 19/200\n",
      "2023-04-03 18:43:49,958 [MainThread  ] [INFO ]  Loading features sequence data into memory 20/200\n",
      "2023-04-03 18:43:49,990 [MainThread  ] [INFO ]  Loading features sequence data into memory 21/200\n",
      "2023-04-03 18:43:50,012 [MainThread  ] [INFO ]  Loading features sequence data into memory 22/200\n",
      "2023-04-03 18:43:50,028 [MainThread  ] [INFO ]  Loading features sequence data into memory 23/200\n",
      "2023-04-03 18:43:50,066 [MainThread  ] [INFO ]  Loading features sequence data into memory 24/200\n",
      "2023-04-03 18:43:50,083 [MainThread  ] [INFO ]  Loading features sequence data into memory 25/200\n",
      "2023-04-03 18:43:50,098 [MainThread  ] [INFO ]  Loading features sequence data into memory 26/200\n",
      "2023-04-03 18:43:50,114 [MainThread  ] [INFO ]  Loading features sequence data into memory 27/200\n",
      "2023-04-03 18:43:50,134 [MainThread  ] [INFO ]  Loading features sequence data into memory 28/200\n",
      "2023-04-03 18:43:50,151 [MainThread  ] [INFO ]  Loading features sequence data into memory 29/200\n",
      "2023-04-03 18:43:50,171 [MainThread  ] [INFO ]  Loading features sequence data into memory 30/200\n",
      "2023-04-03 18:43:50,190 [MainThread  ] [INFO ]  Loading features sequence data into memory 31/200\n",
      "2023-04-03 18:43:50,210 [MainThread  ] [INFO ]  Loading features sequence data into memory 32/200\n",
      "2023-04-03 18:43:50,228 [MainThread  ] [INFO ]  Loading features sequence data into memory 33/200\n",
      "2023-04-03 18:43:50,246 [MainThread  ] [INFO ]  Loading features sequence data into memory 34/200\n",
      "2023-04-03 18:43:50,264 [MainThread  ] [INFO ]  Loading features sequence data into memory 35/200\n",
      "2023-04-03 18:43:50,282 [MainThread  ] [INFO ]  Loading features sequence data into memory 36/200\n",
      "2023-04-03 18:43:50,301 [MainThread  ] [INFO ]  Loading features sequence data into memory 37/200\n",
      "2023-04-03 18:43:50,319 [MainThread  ] [INFO ]  Loading features sequence data into memory 38/200\n",
      "2023-04-03 18:43:50,337 [MainThread  ] [INFO ]  Loading features sequence data into memory 39/200\n",
      "2023-04-03 18:43:50,355 [MainThread  ] [INFO ]  Loading features sequence data into memory 40/200\n",
      "2023-04-03 18:43:50,373 [MainThread  ] [INFO ]  Loading features sequence data into memory 41/200\n",
      "2023-04-03 18:43:50,392 [MainThread  ] [INFO ]  Loading features sequence data into memory 42/200\n",
      "2023-04-03 18:43:50,412 [MainThread  ] [INFO ]  Loading features sequence data into memory 43/200\n",
      "2023-04-03 18:43:50,427 [MainThread  ] [INFO ]  Loading features sequence data into memory 44/200\n",
      "2023-04-03 18:43:50,443 [MainThread  ] [INFO ]  Loading features sequence data into memory 45/200\n",
      "2023-04-03 18:43:50,459 [MainThread  ] [INFO ]  Loading features sequence data into memory 46/200\n",
      "2023-04-03 18:43:50,477 [MainThread  ] [INFO ]  Loading features sequence data into memory 47/200\n",
      "2023-04-03 18:43:50,494 [MainThread  ] [INFO ]  Loading features sequence data into memory 48/200\n",
      "2023-04-03 18:43:50,510 [MainThread  ] [INFO ]  Loading features sequence data into memory 49/200\n",
      "2023-04-03 18:43:50,527 [MainThread  ] [INFO ]  Loading features sequence data into memory 50/200\n",
      "2023-04-03 18:43:50,544 [MainThread  ] [INFO ]  Loading features sequence data into memory 51/200\n",
      "2023-04-03 18:43:50,562 [MainThread  ] [INFO ]  Loading features sequence data into memory 52/200\n",
      "2023-04-03 18:43:50,578 [MainThread  ] [INFO ]  Loading features sequence data into memory 53/200\n",
      "2023-04-03 18:43:50,594 [MainThread  ] [INFO ]  Loading features sequence data into memory 54/200\n",
      "2023-04-03 18:43:50,609 [MainThread  ] [INFO ]  Loading features sequence data into memory 55/200\n",
      "2023-04-03 18:43:50,625 [MainThread  ] [INFO ]  Loading features sequence data into memory 56/200\n",
      "2023-04-03 18:43:50,641 [MainThread  ] [INFO ]  Loading features sequence data into memory 57/200\n",
      "2023-04-03 18:43:50,658 [MainThread  ] [INFO ]  Loading features sequence data into memory 58/200\n",
      "2023-04-03 18:43:50,675 [MainThread  ] [INFO ]  Loading features sequence data into memory 59/200\n",
      "2023-04-03 18:43:50,691 [MainThread  ] [INFO ]  Loading features sequence data into memory 60/200\n",
      "2023-04-03 18:43:50,705 [MainThread  ] [INFO ]  Loading features sequence data into memory 61/200\n",
      "2023-04-03 18:43:50,720 [MainThread  ] [INFO ]  Loading features sequence data into memory 62/200\n",
      "2023-04-03 18:43:50,736 [MainThread  ] [INFO ]  Loading features sequence data into memory 63/200\n",
      "2023-04-03 18:43:50,753 [MainThread  ] [INFO ]  Loading features sequence data into memory 64/200\n",
      "2023-04-03 18:43:50,769 [MainThread  ] [INFO ]  Loading features sequence data into memory 65/200\n",
      "2023-04-03 18:43:50,786 [MainThread  ] [INFO ]  Loading features sequence data into memory 66/200\n",
      "2023-04-03 18:43:50,802 [MainThread  ] [INFO ]  Loading features sequence data into memory 67/200\n",
      "2023-04-03 18:43:50,817 [MainThread  ] [INFO ]  Loading features sequence data into memory 68/200\n",
      "2023-04-03 18:43:50,832 [MainThread  ] [INFO ]  Loading features sequence data into memory 69/200\n",
      "2023-04-03 18:43:50,850 [MainThread  ] [INFO ]  Loading features sequence data into memory 70/200\n",
      "2023-04-03 18:43:50,869 [MainThread  ] [INFO ]  Loading features sequence data into memory 71/200\n",
      "2023-04-03 18:43:50,885 [MainThread  ] [INFO ]  Loading features sequence data into memory 72/200\n",
      "2023-04-03 18:43:50,902 [MainThread  ] [INFO ]  Loading features sequence data into memory 73/200\n",
      "2023-04-03 18:43:50,919 [MainThread  ] [INFO ]  Loading features sequence data into memory 74/200\n",
      "2023-04-03 18:43:50,934 [MainThread  ] [INFO ]  Loading features sequence data into memory 75/200\n",
      "2023-04-03 18:43:50,948 [MainThread  ] [INFO ]  Loading features sequence data into memory 76/200\n",
      "2023-04-03 18:43:50,964 [MainThread  ] [INFO ]  Loading features sequence data into memory 77/200\n",
      "2023-04-03 18:43:50,978 [MainThread  ] [INFO ]  Loading features sequence data into memory 78/200\n",
      "2023-04-03 18:43:50,993 [MainThread  ] [INFO ]  Loading features sequence data into memory 79/200\n",
      "2023-04-03 18:43:51,009 [MainThread  ] [INFO ]  Loading features sequence data into memory 80/200\n",
      "2023-04-03 18:43:51,025 [MainThread  ] [INFO ]  Loading features sequence data into memory 81/200\n",
      "2023-04-03 18:43:51,039 [MainThread  ] [INFO ]  Loading features sequence data into memory 82/200\n",
      "2023-04-03 18:43:51,054 [MainThread  ] [INFO ]  Loading features sequence data into memory 83/200\n",
      "2023-04-03 18:43:51,069 [MainThread  ] [INFO ]  Loading features sequence data into memory 84/200\n",
      "2023-04-03 18:43:51,084 [MainThread  ] [INFO ]  Loading features sequence data into memory 85/200\n",
      "2023-04-03 18:43:51,099 [MainThread  ] [INFO ]  Loading features sequence data into memory 86/200\n",
      "2023-04-03 18:43:51,114 [MainThread  ] [INFO ]  Loading features sequence data into memory 87/200\n",
      "2023-04-03 18:43:51,129 [MainThread  ] [INFO ]  Loading features sequence data into memory 88/200\n",
      "2023-04-03 18:43:51,143 [MainThread  ] [INFO ]  Loading features sequence data into memory 89/200\n",
      "2023-04-03 18:43:51,157 [MainThread  ] [INFO ]  Loading features sequence data into memory 90/200\n",
      "2023-04-03 18:43:51,174 [MainThread  ] [INFO ]  Loading features sequence data into memory 91/200\n",
      "2023-04-03 18:43:51,189 [MainThread  ] [INFO ]  Loading features sequence data into memory 92/200\n",
      "2023-04-03 18:43:51,206 [MainThread  ] [INFO ]  Loading features sequence data into memory 93/200\n",
      "2023-04-03 18:43:51,221 [MainThread  ] [INFO ]  Loading features sequence data into memory 94/200\n",
      "2023-04-03 18:43:51,237 [MainThread  ] [INFO ]  Loading features sequence data into memory 95/200\n",
      "2023-04-03 18:43:51,252 [MainThread  ] [INFO ]  Loading features sequence data into memory 96/200\n",
      "2023-04-03 18:43:51,269 [MainThread  ] [INFO ]  Loading features sequence data into memory 97/200\n",
      "2023-04-03 18:43:51,285 [MainThread  ] [INFO ]  Loading features sequence data into memory 98/200\n",
      "2023-04-03 18:43:51,300 [MainThread  ] [INFO ]  Loading features sequence data into memory 99/200\n",
      "2023-04-03 18:43:51,355 [MainThread  ] [INFO ]  Loading features sequence data into memory 100/200\n",
      "2023-04-03 18:43:51,378 [MainThread  ] [INFO ]  Loading features sequence data into memory 101/200\n",
      "2023-04-03 18:43:51,396 [MainThread  ] [INFO ]  Loading features sequence data into memory 102/200\n",
      "2023-04-03 18:43:51,410 [MainThread  ] [INFO ]  Loading features sequence data into memory 103/200\n",
      "2023-04-03 18:43:51,434 [MainThread  ] [INFO ]  Loading features sequence data into memory 104/200\n",
      "2023-04-03 18:43:51,457 [MainThread  ] [INFO ]  Loading features sequence data into memory 105/200\n",
      "2023-04-03 18:43:51,479 [MainThread  ] [INFO ]  Loading features sequence data into memory 106/200\n",
      "2023-04-03 18:43:51,495 [MainThread  ] [INFO ]  Loading features sequence data into memory 107/200\n",
      "2023-04-03 18:43:51,512 [MainThread  ] [INFO ]  Loading features sequence data into memory 108/200\n",
      "2023-04-03 18:43:51,532 [MainThread  ] [INFO ]  Loading features sequence data into memory 109/200\n",
      "2023-04-03 18:43:51,549 [MainThread  ] [INFO ]  Loading features sequence data into memory 110/200\n",
      "2023-04-03 18:43:51,571 [MainThread  ] [INFO ]  Loading features sequence data into memory 111/200\n",
      "2023-04-03 18:43:51,591 [MainThread  ] [INFO ]  Loading features sequence data into memory 112/200\n",
      "2023-04-03 18:43:51,605 [MainThread  ] [INFO ]  Loading features sequence data into memory 113/200\n",
      "2023-04-03 18:43:51,620 [MainThread  ] [INFO ]  Loading features sequence data into memory 114/200\n",
      "2023-04-03 18:43:51,636 [MainThread  ] [INFO ]  Loading features sequence data into memory 115/200\n",
      "2023-04-03 18:43:51,653 [MainThread  ] [INFO ]  Loading features sequence data into memory 116/200\n",
      "2023-04-03 18:43:51,669 [MainThread  ] [INFO ]  Loading features sequence data into memory 117/200\n",
      "2023-04-03 18:43:51,685 [MainThread  ] [INFO ]  Loading features sequence data into memory 118/200\n",
      "2023-04-03 18:43:51,703 [MainThread  ] [INFO ]  Loading features sequence data into memory 119/200\n",
      "2023-04-03 18:43:51,719 [MainThread  ] [INFO ]  Loading features sequence data into memory 120/200\n",
      "2023-04-03 18:43:51,744 [MainThread  ] [INFO ]  Loading features sequence data into memory 121/200\n",
      "2023-04-03 18:43:51,761 [MainThread  ] [INFO ]  Loading features sequence data into memory 122/200\n",
      "2023-04-03 18:43:51,776 [MainThread  ] [INFO ]  Loading features sequence data into memory 123/200\n",
      "2023-04-03 18:43:51,790 [MainThread  ] [INFO ]  Loading features sequence data into memory 124/200\n",
      "2023-04-03 18:43:51,805 [MainThread  ] [INFO ]  Loading features sequence data into memory 125/200\n",
      "2023-04-03 18:43:51,820 [MainThread  ] [INFO ]  Loading features sequence data into memory 126/200\n",
      "2023-04-03 18:43:51,834 [MainThread  ] [INFO ]  Loading features sequence data into memory 127/200\n",
      "2023-04-03 18:43:51,849 [MainThread  ] [INFO ]  Loading features sequence data into memory 128/200\n",
      "2023-04-03 18:43:51,864 [MainThread  ] [INFO ]  Loading features sequence data into memory 129/200\n",
      "2023-04-03 18:43:51,879 [MainThread  ] [INFO ]  Loading features sequence data into memory 130/200\n",
      "2023-04-03 18:43:51,892 [MainThread  ] [INFO ]  Loading features sequence data into memory 131/200\n",
      "2023-04-03 18:43:51,908 [MainThread  ] [INFO ]  Loading features sequence data into memory 132/200\n",
      "2023-04-03 18:43:51,925 [MainThread  ] [INFO ]  Loading features sequence data into memory 133/200\n",
      "2023-04-03 18:43:51,944 [MainThread  ] [INFO ]  Loading features sequence data into memory 134/200\n",
      "2023-04-03 18:43:51,959 [MainThread  ] [INFO ]  Loading features sequence data into memory 135/200\n",
      "2023-04-03 18:43:51,975 [MainThread  ] [INFO ]  Loading features sequence data into memory 136/200\n",
      "2023-04-03 18:43:51,989 [MainThread  ] [INFO ]  Loading features sequence data into memory 137/200\n",
      "2023-04-03 18:43:52,004 [MainThread  ] [INFO ]  Loading features sequence data into memory 138/200\n",
      "2023-04-03 18:43:52,019 [MainThread  ] [INFO ]  Loading features sequence data into memory 139/200\n",
      "2023-04-03 18:43:52,033 [MainThread  ] [INFO ]  Loading features sequence data into memory 140/200\n",
      "2023-04-03 18:43:52,049 [MainThread  ] [INFO ]  Loading features sequence data into memory 141/200\n",
      "2023-04-03 18:43:52,063 [MainThread  ] [INFO ]  Loading features sequence data into memory 142/200\n",
      "2023-04-03 18:43:52,079 [MainThread  ] [INFO ]  Loading features sequence data into memory 143/200\n",
      "2023-04-03 18:43:52,096 [MainThread  ] [INFO ]  Loading features sequence data into memory 144/200\n",
      "2023-04-03 18:43:52,113 [MainThread  ] [INFO ]  Loading features sequence data into memory 145/200\n",
      "2023-04-03 18:43:52,131 [MainThread  ] [INFO ]  Loading features sequence data into memory 146/200\n",
      "2023-04-03 18:43:52,147 [MainThread  ] [INFO ]  Loading features sequence data into memory 147/200\n",
      "2023-04-03 18:43:52,162 [MainThread  ] [INFO ]  Loading features sequence data into memory 148/200\n",
      "2023-04-03 18:43:52,178 [MainThread  ] [INFO ]  Loading features sequence data into memory 149/200\n",
      "2023-04-03 18:43:52,195 [MainThread  ] [INFO ]  Loading features sequence data into memory 150/200\n",
      "2023-04-03 18:43:52,211 [MainThread  ] [INFO ]  Loading features sequence data into memory 151/200\n",
      "2023-04-03 18:43:52,226 [MainThread  ] [INFO ]  Loading features sequence data into memory 152/200\n",
      "2023-04-03 18:43:52,241 [MainThread  ] [INFO ]  Loading features sequence data into memory 153/200\n",
      "2023-04-03 18:43:52,257 [MainThread  ] [INFO ]  Loading features sequence data into memory 154/200\n",
      "2023-04-03 18:43:52,274 [MainThread  ] [INFO ]  Loading features sequence data into memory 155/200\n",
      "2023-04-03 18:43:52,290 [MainThread  ] [INFO ]  Loading features sequence data into memory 156/200\n",
      "2023-04-03 18:43:52,305 [MainThread  ] [INFO ]  Loading features sequence data into memory 157/200\n",
      "2023-04-03 18:43:52,323 [MainThread  ] [INFO ]  Loading features sequence data into memory 158/200\n",
      "2023-04-03 18:43:52,340 [MainThread  ] [INFO ]  Loading features sequence data into memory 159/200\n",
      "2023-04-03 18:43:52,356 [MainThread  ] [INFO ]  Loading features sequence data into memory 160/200\n",
      "2023-04-03 18:43:52,371 [MainThread  ] [INFO ]  Loading features sequence data into memory 161/200\n",
      "2023-04-03 18:43:52,385 [MainThread  ] [INFO ]  Loading features sequence data into memory 162/200\n",
      "2023-04-03 18:43:52,402 [MainThread  ] [INFO ]  Loading features sequence data into memory 163/200\n",
      "2023-04-03 18:43:52,419 [MainThread  ] [INFO ]  Loading features sequence data into memory 164/200\n",
      "2023-04-03 18:43:52,438 [MainThread  ] [INFO ]  Loading features sequence data into memory 165/200\n",
      "2023-04-03 18:43:52,458 [MainThread  ] [INFO ]  Loading features sequence data into memory 166/200\n",
      "2023-04-03 18:43:52,475 [MainThread  ] [INFO ]  Loading features sequence data into memory 167/200\n",
      "2023-04-03 18:43:52,490 [MainThread  ] [INFO ]  Loading features sequence data into memory 168/200\n",
      "2023-04-03 18:43:52,507 [MainThread  ] [INFO ]  Loading features sequence data into memory 169/200\n",
      "2023-04-03 18:43:52,524 [MainThread  ] [INFO ]  Loading features sequence data into memory 170/200\n",
      "2023-04-03 18:43:52,541 [MainThread  ] [INFO ]  Loading features sequence data into memory 171/200\n",
      "2023-04-03 18:43:52,557 [MainThread  ] [INFO ]  Loading features sequence data into memory 172/200\n",
      "2023-04-03 18:43:52,571 [MainThread  ] [INFO ]  Loading features sequence data into memory 173/200\n",
      "2023-04-03 18:43:52,587 [MainThread  ] [INFO ]  Loading features sequence data into memory 174/200\n",
      "2023-04-03 18:43:52,602 [MainThread  ] [INFO ]  Loading features sequence data into memory 175/200\n",
      "2023-04-03 18:43:52,616 [MainThread  ] [INFO ]  Loading features sequence data into memory 176/200\n",
      "2023-04-03 18:43:52,631 [MainThread  ] [INFO ]  Loading features sequence data into memory 177/200\n",
      "2023-04-03 18:43:52,646 [MainThread  ] [INFO ]  Loading features sequence data into memory 178/200\n",
      "2023-04-03 18:43:52,664 [MainThread  ] [INFO ]  Loading features sequence data into memory 179/200\n",
      "2023-04-03 18:43:52,678 [MainThread  ] [INFO ]  Loading features sequence data into memory 180/200\n",
      "2023-04-03 18:43:52,693 [MainThread  ] [INFO ]  Loading features sequence data into memory 181/200\n",
      "2023-04-03 18:43:52,708 [MainThread  ] [INFO ]  Loading features sequence data into memory 182/200\n",
      "2023-04-03 18:43:52,726 [MainThread  ] [INFO ]  Loading features sequence data into memory 183/200\n",
      "2023-04-03 18:43:52,742 [MainThread  ] [INFO ]  Loading features sequence data into memory 184/200\n",
      "2023-04-03 18:43:52,760 [MainThread  ] [INFO ]  Loading features sequence data into memory 185/200\n",
      "2023-04-03 18:43:52,775 [MainThread  ] [INFO ]  Loading features sequence data into memory 186/200\n",
      "2023-04-03 18:43:52,792 [MainThread  ] [INFO ]  Loading features sequence data into memory 187/200\n",
      "2023-04-03 18:43:52,811 [MainThread  ] [INFO ]  Loading features sequence data into memory 188/200\n",
      "2023-04-03 18:43:52,828 [MainThread  ] [INFO ]  Loading features sequence data into memory 189/200\n",
      "2023-04-03 18:43:52,845 [MainThread  ] [INFO ]  Loading features sequence data into memory 190/200\n",
      "2023-04-03 18:43:52,861 [MainThread  ] [INFO ]  Loading features sequence data into memory 191/200\n",
      "2023-04-03 18:43:52,877 [MainThread  ] [INFO ]  Loading features sequence data into memory 192/200\n",
      "2023-04-03 18:43:52,894 [MainThread  ] [INFO ]  Loading features sequence data into memory 193/200\n",
      "2023-04-03 18:43:52,910 [MainThread  ] [INFO ]  Loading features sequence data into memory 194/200\n",
      "2023-04-03 18:43:52,926 [MainThread  ] [INFO ]  Loading features sequence data into memory 195/200\n",
      "2023-04-03 18:43:52,941 [MainThread  ] [INFO ]  Loading features sequence data into memory 196/200\n",
      "2023-04-03 18:43:52,956 [MainThread  ] [INFO ]  Loading features sequence data into memory 197/200\n",
      "2023-04-03 18:43:52,973 [MainThread  ] [INFO ]  Loading features sequence data into memory 198/200\n",
      "2023-04-03 18:43:52,990 [MainThread  ] [INFO ]  Loading features sequence data into memory 199/200\n",
      "2023-04-03 18:43:53,005 [MainThread  ] [INFO ]  Loading features sequence data into memory 200/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=32580, valid=1810, test=1810\n"
     ]
    }
   ],
   "source": [
    "be_data = Data(\n",
    "    sequence_length = experiment['sequence_length'],\n",
    "    return_CNN_features = True, \n",
    "    pretrained_model_name = experiment['pretrained_model_name'],\n",
    "    pooling = experiment['pooling'],\n",
    "    frame_size = experiment['frame_size'],\n",
    "    custom_model_name= experiment['custom_model_name'],\n",
    "    return_generator = False,\n",
    "    _bed = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete existing results\n",
    "if os.path.exists(DNN_lib_path + '/models/' + str(experiment[\"model_id\"]) + '/results.json'):\n",
    "    rmtree(DNN_lib_path + '/models/' + str(experiment[\"model_id\"]) + '/')\n",
    "# create models folder if doesn't exist\n",
    "if not os.path.exists(DNN_lib_path + '/models/'):\n",
    "    os.makedirs(DNN_lib_path + '/models/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-03 18:47:12,973 [MainThread  ] [INFO ]  Model folder exists but no results found - potential error in previous model training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1   XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "{'architecture': 'video_mlp_concat', 'dropout': 0.2, 'layer_1_size': 256, 'layer_2_size': 512, 'layer_3_size': 256, 'model_id': 1, 'pooling': 'max', 'pretrained_model_name': 'resnet50', 'custom_model_name': 'ResNet50_pop_grids', 'path_features': '/cache/ResNet50_pop_grids', 'sequence_length': 20, 'sequence_model': 'LSTM', 'sequence_model_layers': 3, 'frame_size': (32, 32)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-03 18:47:13.196499: E tensorflow/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2023-04-03 18:47:13.197606: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: pop-os\n",
      "2023-04-03 18:47:13.197621: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: pop-os\n",
      "2023-04-03 18:47:13.198091: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 525.85.5\n",
      "2023-04-03 18:47:13.199057: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 525.85.5\n",
      "2023-04-03 18:47:13.199068: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 525.85.5\n",
      "2023-04-03 18:47:13.210678: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "print(str(experiment[\"model_id\"]) + \"   \" + \"X\"*60)\n",
    "print(experiment)\n",
    "\n",
    "architecture = Architecture(model_id = experiment['model_id'], \n",
    "                            architecture = 'video_lrcnn_frozen', \n",
    "                            sequence_length = experiment['sequence_length'], \n",
    "                            pretrained_model_name = experiment['pretrained_model_name'],\n",
    "                            custom_model_name = experiment['custom_model_name'],\n",
    "                            pooling = experiment['pooling'],\n",
    "                            sequence_model = experiment['sequence_model'],\n",
    "                            sequence_model_layers = experiment['sequence_model_layers'],\n",
    "                            layer_1_size = experiment['layer_1_size'],\n",
    "                            layer_2_size = experiment['layer_2_size'],\n",
    "                            layer_3_size = experiment['layer_3_size'],\n",
    "                            dropout = experiment['dropout'],\n",
    "                            _bed = True,\n",
    "                            verbose=True,\n",
    "                            data = be_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-03 18:47:14.905027: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 5337907200 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.82265, saving model to /home/tiesbarendse/Documents/00_Uni/22_23/pap/Deep-Neural-Networks-for-Video-Classification/notebooks/../models/1/model_round_1.h5\n",
      "\n",
      "Epoch 2: val_accuracy improved from 0.82265 to 0.83425, saving model to /home/tiesbarendse/Documents/00_Uni/22_23/pap/Deep-Neural-Networks-for-Video-Classification/notebooks/../models/1/model_round_1.h5\n",
      "\n",
      "Epoch 3: val_accuracy improved from 0.83425 to 0.83702, saving model to /home/tiesbarendse/Documents/00_Uni/22_23/pap/Deep-Neural-Networks-for-Video-Classification/notebooks/../models/1/model_round_1.h5\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.83702\n",
      "\n",
      "Epoch 5: val_accuracy did not improve from 0.83702\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 0.83702\n",
      "Epoch 6: early stopping\n",
      "H1 {'loss': [0.22107233107089996, 0.19697020947933197, 0.19114236533641815, 0.18833491206169128, 0.18994078040122986, 0.18175280094146729], 'accuracy': [0.7420810461044312, 0.7761203050613403, 0.7814303040504456, 0.7846531867980957, 0.7841620445251465, 0.792879045009613], 'val_loss': [0.15678101778030396, 0.15201349556446075, 0.15191717445850372, 0.1723202019929886, 0.17058387398719788, 0.18619711697101593], 'val_accuracy': [0.8226519227027893, 0.8342541456222534, 0.8370165824890137, 0.7977900505065918, 0.8077347874641418, 0.779558002948761]}\n",
      "stopped_epoch1 3\n",
      "6\n",
      "0.7977900505065918\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "architecture.train_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "8f9fd7e5cd0ee174f389b9d7efcf5e4e8d178ce255061fb4046125c712618101"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
